<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>线性表</title>
    <url>/2020/07/01/%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h1><blockquote>
<p>定义: 零个或有多个元素的有限序列</p>
</blockquote>
<p><img src="https://i.loli.net/2020/07/03/49MFwX8VzsOfIW1.png" alt="image-20200703165948756"></p>
<a id="more"></a>
<h2 id="1-线性表的顺序存储结构"><a href="#1-线性表的顺序存储结构" class="headerlink" title="1. 线性表的顺序存储结构"></a>1. 线性表的顺序存储结构</h2><p>线性表的顺序存储结构指的是用一段地址连续的存储单元一次存储线性表的数据元素.</p>
<h3 id="1-1-数据存储方式"><a href="#1-1-数据存储方式" class="headerlink" title="1.1 数据存储方式"></a>1.1 数据存储方式</h3><p>在C语言中使用一维数组存储</p>
<ul>
<li>数组的长度: 存放线性表的存储空间长度, 即capacity()</li>
<li>线性表的长度: 线性表中数据元素的个数, 即size()</li>
</ul>
<p>任意时刻线性表的长度应该小于等于数组长度</p>
<p>如果已知线性表的首元素a1地址, 可以通过下列公式算出第i个数据元素:</p>
<script type="math/tex; mode=display">
LOC(a_i) = LOC(a_1) + (i-1)C</script><p>则不论ai位于何处 , 计算地址的时间都是相同的, <strong>时间复杂度为$O(1)$,</strong> 具有这一特点的存储结构称为随机存储. 比如数组, </p>
<h3 id="1-2-插入和删除"><a href="#1-2-插入和删除" class="headerlink" title="1.2 插入和删除"></a>1.2 插入和删除</h3><p>插入算法的思路:</p>
<ol>
<li>如果插入位置不合理, 抛出异常</li>
<li>如果线性表长度大于或者等于数组长度, 抛出异常或者动态增加容量</li>
<li>从最后一个元素向前遍历到第i个位置, 分别将他们都向后移动一个位置, 从后向前遍历是为了避免被覆盖</li>
<li>将要插入的元素填入位置i处</li>
<li>表长增加1</li>
</ol>
<p>删除算法的思路:</p>
<ol>
<li>如果删除的位置不合理, 抛出异常</li>
<li>取出删除元素</li>
<li>从删除元素位置开始遍历到最后一个元素位置, 将他们都向前移动一位</li>
<li>表长减1</li>
</ol>
<p>时间复杂度:</p>
<p>最好情况是插入最后一个或者删除第一个, 时间复杂度为$O(1)$, 最坏情况则相反, 时间复杂度为$O(n)$, 平均需要的移动次数为$\frac{n-1}{2}$.</p>
<p>因此<strong>顺序存储结构的插入和删除,时间复杂度为$O(n)$.</strong></p>
<h3 id="1-3-优缺点"><a href="#1-3-优缺点" class="headerlink" title="1.3 优缺点"></a>1.3 优缺点</h3><div class="table-container">
<table>
<thead>
<tr>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>不需要为表中元素逻辑关系增加额外存储空间</td>
<td>插入和删除操作需要移动大量元素</td>
</tr>
<tr>
<td>可以快速存取表中任一元素</td>
<td>线性表长度大时, 难以确定存储空间容量</td>
</tr>
<tr>
<td></td>
<td>造成存储空间的”碎片”</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-链式存储结构"><a href="#2-链式存储结构" class="headerlink" title="2. 链式存储结构"></a>2. 链式存储结构</h2><h3 id="2-1-链表的定义和存储结构"><a href="#2-1-链表的定义和存储结构" class="headerlink" title="2.1 链表的定义和存储结构"></a>2.1 链表的定义和存储结构</h3><p>数据元素ai除了要<strong>存储本身的信息</strong>外, 还需要<strong>存储后续元素地址</strong>. 我们把存储数据元素信息的域称为数据域, 存储后继元素位置的域称为指针域, 指针域存储的是后继结点的指针. 这两部分组成ai的存储印象, 称为<strong>结点.</strong></p>
<p>链表中的第一个元素的存储位置称为<strong>头指针</strong>, 不过通常会在单链表的第一个结点之间附设一个结点(懒结点)作为头结点, 头结点数据域可以不存储信息, 通常是为了处理特殊情况(如空链表或者只有一个元素的链表)而引入.</p>
<p>单链表中最后一个结点的指针指向”空”.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>头节点</th>
<th>头指针</th>
</tr>
</thead>
<tbody>
<tr>
<td>为了操作方便和统一引入,一般放在第一元素节点之前. 数据域一般无意义(也可存放链表长度)</td>
<td>指向第一个节点的指针, 若链表有头节点, 则是指向头节点的指针</td>
</tr>
<tr>
<td>有了头结点, 在第一元素节点前插入节点或者删除第一节点的操作就和其他节点统一了</td>
<td>具有标识作用, 通常用头指针冠以链表的名字</td>
</tr>
<tr>
<td>无论链表是否为空, 头指针均不为空</td>
<td>头节点不是链表的必要元素(如空链表)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-2-单链表的读取"><a href="#2-2-单链表的读取" class="headerlink" title="2.2 单链表的读取"></a>2.2 单链表的读取</h3><p>获得链表第i个数据的思路:</p>
<ol>
<li>声明一个指针p指向链表的第一个结点</li>
<li>遍历链表, 让p不断指向下一结点</li>
<li>若遍历到链表末尾p为空, 则第i个节点不存在</li>
<li>若查找到, 返回结点p的数据</li>
</ol>
<p>主要的核心思想是<strong>工作指针后移</strong>, 每次查找都要遍历链表, 因此时间复杂度为$O(n)$</p>
<h3 id="2-3-单链表的插入和删除"><a href="#2-3-单链表的插入和删除" class="headerlink" title="2.3 单链表的插入和删除"></a>2.3 单链表的插入和删除</h3><p><strong>插入</strong></p>
<p>在结点p和结点p-&gt;next之间插入节点s, 只需要<code>s-&gt;next=p-&gt;next; p-&gt;next-&gt;s;//顺序不能错</code></p>
<p>单链表在第i个数据插入节点元素为e的节点s</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">LinkList</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> data;</span><br><span class="line">  	LinkList* next;</span><br><span class="line">    LinkList(<span class="keyword">int</span> data) : data(data) , next(<span class="literal">nullptr</span>)&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">LinkList* <span class="title">ListInsert</span><span class="params">(LinkList* L, <span class="keyword">int</span> i, Elem e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> j=<span class="number">1</span>;</span><br><span class="line">    LinkList* p,s;</span><br><span class="line">    p = L;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span>( p &amp;&amp; j&lt;i) <span class="comment">//寻找第i个节点</span></span><br><span class="line">    &#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        ++j;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(!p||j&gt;i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    s=<span class="keyword">new</span> LinkList(e);</span><br><span class="line">    s-&gt;next = p-&gt;next;	<span class="comment">//</span></span><br><span class="line">    p-&gt;next = s;		<span class="comment">//两句的顺序不能颠倒</span></span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>删除</strong></p>
<p>若要利用节点q去删除节点p的后一个节点, 只需要<code>q = p-&gt;next; q-&gt;next = p-&gt;next;</code>,即使用保留将要删除的节点, 然后使用<code>q-&gt;next = p-&gt;next;</code>进行删除.</p>
<p>单链表删除第i个数据结点的算法如下:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">LinkList</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> data;</span><br><span class="line">  	LinkList* next;</span><br><span class="line">    LinkList(<span class="keyword">int</span> data) : data(data) , next(<span class="literal">nullptr</span>)&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">ElemType <span class="title">ListInsert</span><span class="params">(LinkList* L, <span class="keyword">int</span> i, ElemType* e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> j=<span class="number">1</span>;</span><br><span class="line">    LinkList* p,q;</span><br><span class="line">    p = L;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span>( p-&gt;next &amp;&amp; j&lt;i) <span class="comment">//寻找第i-1个节点</span></span><br><span class="line">    &#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        ++j;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(!p-&gt;next||j&gt;i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;	<span class="comment">//第i个结点不存在</span></span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">    q=p-&gt;next;</span><br><span class="line">    p-&gt;next=q-&gt;next;</span><br><span class="line">    *e=q-&gt;data;</span><br><span class="line">    <span class="keyword">delete</span> q;</span><br><span class="line">    <span class="keyword">return</span> *e</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>单链表的插入和删除时间复杂度为O(1), 对于插入和删除数据越频繁的操作, 单链表的效率优势就越明显.</strong></p>
<h3 id="2-4-单链表的整表创建"><a href="#2-4-单链表的整表创建" class="headerlink" title="2.4 单链表的整表创建"></a>2.4 单链表的整表创建</h3><p>算法思路:</p>
<ol>
<li>声明有一指针p和计数器变量i</li>
<li>初始化一空链表L</li>
<li>让L的头节点的指针指向NULL, 即建立一个带头结点的空链表</li>
<li>循环:<ol>
<li>生成一新节点p</li>
<li>随机生成一数字赋值给p的数据域p-&gt;data</li>
<li>将p插入到头结点<strong>与前一新节点之间</strong>(头插法), 也可将新结点插入到<strong>终端节点的后面</strong>(尾插法)</li>
</ol>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">LinkList</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> data;</span><br><span class="line">  	LinkList* next;</span><br><span class="line">    LinkList(<span class="keyword">int</span> data) : data(data) , next(<span class="literal">nullptr</span>)&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">creatList</span><span class="params">(LinkList* L, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LinkList p;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    srand(time(<span class="number">0</span>));</span><br><span class="line">    L = <span class="keyword">new</span> LinkList(<span class="number">0</span>);</span><br><span class="line">    L-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        p = <span class="keyword">new</span> LinkList(rand()%<span class="number">100</span>+<span class="number">1</span>);</span><br><span class="line">        p-&gt;next = L-&gt;next;</span><br><span class="line">        L-&gt;next = p;			<span class="comment">//插入到表头</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">creatList</span><span class="params">(LinkList* L, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LinkList p,r;</span><br><span class="line">    srand(time(<span class="number">0</span>));</span><br><span class="line">    L = <span class="keyword">new</span> LinkList(<span class="number">0</span>);</span><br><span class="line">    L-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">    r = L;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        p = <span class="keyword">new</span> LinkList(rand()%<span class="number">100</span>+<span class="number">1</span>);</span><br><span class="line">        r-&gt;next = p;</span><br><span class="line">        r = p;			<span class="comment">//插入到表头</span></span><br><span class="line">    &#125;</span><br><span class="line">    r-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-5-单链表的整表删除"><a href="#2-5-单链表的整表删除" class="headerlink" title="2.5 单链表的整表删除"></a>2.5 单链表的整表删除</h3><p>算法思路:</p>
<ol>
<li>声明一个节点p和q</li>
<li>将第一个节点的值赋给p</li>
<li>循环:<ol>
<li>将下一结点的值赋给q;</li>
<li>释放p</li>
<li>将q赋值给p</li>
</ol>
</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">delete</span><span class="params">(LinkList* L)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LinkList p,q;</span><br><span class="line">	p = L;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(p)</span><br><span class="line">    &#123;</span><br><span class="line">        q = p-&gt;next;</span><br><span class="line">        <span class="keyword">delete</span> p;</span><br><span class="line">        p = q;			<span class="comment">//插入到表头</span></span><br><span class="line">    &#125;</span><br><span class="line">    L-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-单链表与顺序存储结构的优缺点"><a href="#3-单链表与顺序存储结构的优缺点" class="headerlink" title="3. 单链表与顺序存储结构的优缺点"></a>3. 单链表与顺序存储结构的优缺点</h2><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>单链表</th>
<th>顺序存储结构</th>
</tr>
</thead>
<tbody>
<tr>
<td>存储分配方式</td>
<td>链式存储, 任意存储位置</td>
<td>顺序存储单元依次存储</td>
</tr>
<tr>
<td>时间性能</td>
<td>查找O(n), 增删O(1)</td>
<td>查找O(1), 增删O(n)</td>
</tr>
<tr>
<td>空间性能</td>
<td>不需要预分配空间, 元素个数不受限</td>
<td>需要预分配空间, 存储空间过小则溢出,过大则浪费</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>一般频繁读取不需要修改的数据采用顺序存储结构, 需要经常删改的结构可以采用链表</li>
<li>当线性元素个数变化较大或者不知道大小时最好采用单链表结构, 如果预先知道存储空间大小可以采用顺序存储结构</li>
</ul>
<h2 id="4-循环链表"><a href="#4-循环链表" class="headerlink" title="4.循环链表"></a>4.循环链表</h2><p>将单链表终端结点的指针端由指向空指针改为指向头结点, 就使整个单链表形成一个环, 这种头尾相接的链表<strong>称为单循环链表</strong>, 简称循环链表.</p>
<p>循环链表和单链表的主要差异在循环的判断条件上</p>
<ul>
<li>对于单链表是判断p-&gt;next是否为NULL</li>
<li>对于循环链表是判断p-&gt;next是否为头结点</li>
</ul>
<p>在链表中, 找到头结点需要O(1)时间, 但是找到最后一个节点需要O(n)时间, 再循环链表中不用头指针, 而是用指向终端节点的尾指针来表示循环链表. 这样可以方便的查找到开始节点和终端节点.</p>
<p>终端节点用尾指针<code>rear</code>表示</p>
<p>那么开始节点为<code>rear-&gt;next-&gt;next</code>注: 第一个next是头结点,开始节点是头结点的后一个, 二者的区别可见2.1节 </p>
<h2 id="5-双向链表"><a href="#5-双向链表" class="headerlink" title="5. 双向链表"></a>5. 双向链表</h2><p>双向链表在每个结点中, 在设置一个指向其前驱结点的指针</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">DulNode</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    DualNode* prior;</span><br><span class="line">    DualNode* next;</span><br><span class="line">&#125; *DualLinkList;</span><br></pre></td></tr></table></figure>
<h3 id="5-1-插入节点"><a href="#5-1-插入节点" class="headerlink" title="5.1 插入节点"></a>5.1 插入节点</h3><p>在p和p-&gt;next之间插入结点s.</p>
<ol>
<li>将p设置为s的前驱</li>
<li>将p-&gt;next设置为s的后驱</li>
<li>将s设置为p-&gt;next的前驱</li>
<li>将s设置为p的后驱</li>
</ol>
<p>要严格注意顺序, 以免p-&gt;next没有指针指向</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">s-&gt;prior = p;</span><br><span class="line">s-&gt;next = p-&gt;next;</span><br><span class="line">p-&gt;next-&gt;prior = s;</span><br><span class="line">p-&gt;next = s;</span><br></pre></td></tr></table></figure>
<h3 id="5-2-删除结点"><a href="#5-2-删除结点" class="headerlink" title="5.2 删除结点"></a>5.2 删除结点</h3><p>删除节点p的步骤</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">p-&gt;prior-&gt;next = p-&gt;next;</span><br><span class="line">p-&gt;next-&gt;prior = p-&gt;prior;</span><br><span class="line"><span class="keyword">delete</span> p;</span><br></pre></td></tr></table></figure>
<h2 id="6-静态链表"><a href="#6-静态链表" class="headerlink" title="6. 静态链表"></a>6. 静态链表</h2><p>静态链表使用数组描述, 主要是为了给没有指针的高级语言设计一种实现单链表能力的方法, 理解其思想即可.</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>计算力参数FLOPS,GOPS,GMACS辨析</title>
    <url>/2020/06/16/%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%8F%82%E6%95%B0FLOPS-GOPS-GMACS%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="FLOPS"><a href="#FLOPS" class="headerlink" title="FLOPS"></a>FLOPS</h2><p>FLOPS是“每秒所执行的浮点运算次数”（floating-point operations per second）的缩写。它常被用来估算电脑的执行效能，尤其是在使用到大量浮点运算的科学计算领域中。正因为FLOPS字尾的那个S，代表秒，而不是复数，所以不能省略掉。</p>
<p>在这里所谓的“浮点运算”，实际上包括了所有涉及小数的运算。这类运算在某类应用软件中常常出现，而它们也比整数运算更花时间。现今大部分的处理器中，都有一个专门用来处理浮点运算的“浮点运算器”（FPU）。也因此FLOPS所量测的，实际上就是FPU的执行速度。而最常用来测量FLOPS的基准程式（benchmark）之一，就是Linpack。</p>
<p>使用时常加数量级前缀如M, G, T等。</p>
<a id="more"></a>
<h2 id="OPS"><a href="#OPS" class="headerlink" title="OPS"></a>OPS</h2><p>OPS与FLOPS类似，只不过OPS一个是操作次数，FLOPS一个是浮点操作次数。</p>
<p>使用时常加数量级前缀如M, G, T等。</p>
<h2 id="MACS"><a href="#MACS" class="headerlink" title="MACS"></a>MACS</h2><p>MACS 指每秒执行的定点<strong>乘累加</strong>操作次数的缩写，它是衡量计算机定点处理能力的量，这个量经常用在那些需要大量定点乘法累加运算的科学运算中，记为MACS。</p>
<p>使用时常加数量级前缀如M, G, T等。</p>
<h2 id="易混辨析—FLOPS-FLOPs-FLOP-s"><a href="#易混辨析—FLOPS-FLOPs-FLOP-s" class="headerlink" title="易混辨析—FLOPS,FLOPs,FLOP/s"></a>易混辨析—FLOPS,FLOPs,FLOP/s</h2><p>FLOPS：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。</p>
<p>FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。</p>
<p>FLOP/s：等同于FLOPS。</p>
<p>简化到计算机只拥有一块CPU的情况时，可以使用以下公式：</p>
<script type="math/tex; mode=display">
{\displaystyle {\text{FLOPS}}={\text{cores}}\times {\frac {\text{cycles}}{\text{second}}}\times {\frac {\text{FLOPs}}{\text{cycle}}}}</script><p>同样的对于OPS和MACS也适用上述规则。</p>
]]></content>
      <categories>
        <category>神经网络加速器</category>
      </categories>
      <tags>
        <tag>神经网络加速器</tag>
        <tag>计算机体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo主题美化</title>
    <url>/2020/06/14/1_Hexo/Hexo%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96/</url>
    <content><![CDATA[<h1 id="Hexo美化"><a href="#Hexo美化" class="headerlink" title="Hexo美化"></a>Hexo美化</h1><h2 id="修改网站图标"><a href="#修改网站图标" class="headerlink" title="修改网站图标"></a>修改网站图标</h2><h3 id="1-实现效果"><a href="#1-实现效果" class="headerlink" title="1. 实现效果"></a>1. 实现效果</h3><p>   <img src="https://i.loli.net/2020/06/14/Z4eQtNWaku6gzdh.png" alt="image-20200614211627199" style="zoom:67%;" div align=center/></p>
<h3 id="2-实现方法"><a href="#2-实现方法" class="headerlink" title="2. 实现方法"></a>2. 实现方法</h3><p>制作或者下载自己的网站图标，这里推荐几个免费的图标下载网站. </p>
<p><a href="https://fontawesome.com/" target="_blank" rel="noopener">Font Awesome</a></p>
<p><a href="https://icons8.com/" target="_blank" rel="noopener">Download free icons, music, stock photos, vectors</a></p>
<p><a href="https://illustrio.com/" target="_blank" rel="noopener">illustrio: 100% free, 100% customizable icon library</a></p>
<p><a href="https://www.iconfont.cn/?spm=a313x.7781069.1998910419.d4d0a486a" target="_blank" rel="noopener">https://www.iconfont.cn/?spm=a313x.7781069.1998910419.d4d0a486a</a></p>
<p>下载的图标最好是32x32和16x16的,  将它们放进<code>/themes/next/source/images/</code>中, 在主题config文件搜索favicon, 进行如下修改</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">favicon:</span></span><br><span class="line">  <span class="comment"># small: /images/favicon-16x16-next.png</span></span><br><span class="line">  <span class="comment"># medium: /images/favicon-32x32-next.png</span></span><br><span class="line">  <span class="attr">small:</span> <span class="string">/images/你的图标名(16x16)</span></span><br><span class="line">  <span class="attr">medium:</span> <span class="string">/images/你的图标名(32x32)</span></span><br></pre></td></tr></table></figure>
<h2 id="修改Next主题底部标签的-号"><a href="#修改Next主题底部标签的-号" class="headerlink" title="修改Next主题底部标签的#号"></a>修改Next主题底部标签的#号</h2><h3 id="1-实现效果-1"><a href="#1-实现效果-1" class="headerlink" title="1. 实现效果"></a>1. 实现效果</h3><p><img src="https://i.loli.net/2020/06/14/gu2OWawqbG1ZhzM.png" alt="image-20200614105134514" style="zoom: 67%;" /></p>
<h3 id="2-实现方法-1"><a href="#2-实现方法-1" class="headerlink" title="2. 实现方法"></a>2. 实现方法</h3><p>打开 <code>/themes/next/layout/_macro/post.swig</code>，搜索 <code>rel=&quot;tag&quot;&gt; </code>，将 <code></code> 换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code></p>
<h2 id="添加社交图标"><a href="#添加社交图标" class="headerlink" title="添加社交图标"></a>添加社交图标</h2><h3 id="1-实现效果-2"><a href="#1-实现效果-2" class="headerlink" title="1. 实现效果"></a>1. 实现效果</h3><h3 id="2-实现方法-2"><a href="#2-实现方法-2" class="headerlink" title="2. 实现方法"></a>2. 实现方法</h3><p>在主题config文件中搜索social, 取消相应注释即可.</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">social:</span></span><br><span class="line">  <span class="comment"># GitHub: https://github.com/shawer96 || github</span></span><br><span class="line">  <span class="comment"># E-Mail: mailto:yourname@gmail.com || envelope</span></span><br><span class="line">  <span class="comment"># Weibo: https://weibo.com/yourname || weibo</span></span><br><span class="line">  <span class="comment">#Google: https://plus.google.com/yourname || google</span></span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/yourname || twitter</span></span><br><span class="line">  <span class="comment">#FB Page: https://www.facebook.com/yourname || facebook</span></span><br><span class="line">  <span class="comment">#StackOverflow: https://stackoverflow.com/yourname || stack-overflow</span></span><br><span class="line">  <span class="comment">#YouTube: https://youtube.com/yourname || youtube</span></span><br><span class="line">  <span class="comment">#Instagram: https://instagram.com/yourname || instagram</span></span><br><span class="line">  <span class="comment">#Skype: skype:yourname?call|chat || skype</span></span><br><span class="line">  <span class="comment">#RSS: /atom.xml || rss</span></span><br></pre></td></tr></table></figure>
<p>也可按照<code>名称: 链接地址 || 社交图标</code>的格式自定义其他的社交账号, 其中<code>||</code>后面的图标是其在<a href="https://fontawesome.com/" target="_blank" rel="noopener">Font Awesome</a>中对应的图标名, 不需要下载.</p>
<h2 id="文章加锁"><a href="#文章加锁" class="headerlink" title="文章加锁"></a>文章加锁</h2><h3 id="1-实现效果-3"><a href="#1-实现效果-3" class="headerlink" title="1.实现效果"></a>1.实现效果</h3><p><img src="https://i.loli.net/2020/06/14/BH3mvAxdMb9l4Yc.png" alt="image-20200614215553079"></p>
<h3 id="2-实现方法-3"><a href="#2-实现方法-3" class="headerlink" title="2. 实现方法"></a>2. 实现方法</h3><ol>
<li>下载加密插件</li>
</ol>
<p>   进入hexo根目录，使用<code>npm install hexo-blog-encrypt</code>命令安装插件。</p>
<ol>
<li>修改配置文件</li>
</ol>
<p>​        在hexo根目录下的config文件中, 添加</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">encrypt:</span></span><br><span class="line">	<span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<ol>
<li>在文章属性栏中添加相应字段</li>
</ol>
<p><img src="https://i.loli.net/2020/06/14/Y6PVFjne9cHlzhy.png" alt="image-20200614215627622" style="zoom: 67%;" /></p>
<p>​    password:  文章的密码</p>
<p>​    message: 输入密码界面提示说明.</p>
<p>​    abstract: 文章界面介绍.</p>
<p>​    message和abstract可以省略.</p>
<h2 id="折叠首页文章"><a href="#折叠首页文章" class="headerlink" title="折叠首页文章"></a>折叠首页文章</h2><h3 id="1-实现效果-4"><a href="#1-实现效果-4" class="headerlink" title="1. 实现效果"></a>1. 实现效果</h3><p><img src="https://i.loli.net/2020/06/14/CcZoB8XpVUJkHNr.png" alt="image-20200614220006815" style="zoom:67%;" /></p>
<h3 id="2-实现方法-4"><a href="#2-实现方法-4" class="headerlink" title="2.实现方法"></a>2.实现方法</h3><ol>
<li><del>已失效, 修改主题config文件中的</del></li>
</ol>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">auto_excerpt:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">length:</span> <span class="number">150</span></span><br></pre></td></tr></table></figure>
<p>​        随着Next主题的更新, 这一方法不再有用.</p>
<ol>
<li>在文章中的属性栏中添加description，并提供文章摘录</li>
</ol>
<p>   这种方式只会在首页列表中显示文章的摘要内容，进入文章详情后不会再显示</p>
<p>   <img src="https://i.loli.net/2020/06/15/3YIW8ZFi7DJVTq6.png" alt="image-20200615000644376" style="zoom: 67%;" /></p>
<ol>
<li>在文章中使用<code>&lt; !--more--&gt;</code> 手动进行截断</li>
</ol>
<p>   这种方法可以根据文章的内容，自己在合适的位置添加 <code>&lt; !--more--&gt;</code> 标签，使用灵活，也是Hexo推荐的方法</p>
<p>​        <img src="https://i.loli.net/2020/06/14/hqtfdeRPaTrx7Dj.png" alt="image-20200614220921108"></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>git使用教程</title>
    <url>/2019/12/30/2_git/git%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="git使用教程"><a href="#git使用教程" class="headerlink" title="git使用教程"></a>git使用教程</h1><h2 id="1-为什么要使用git和github"><a href="#1-为什么要使用git和github" class="headerlink" title="1.为什么要使用git和github"></a>1.为什么要使用git和github</h2><p>无论是写文档还是码代码，你一定遇到过这些情况：某句我想先删掉，但是我又怕找不回来了怎么办？我有别的想法，但是又不敢随便改动这段代码怎么办？我在稳定的代码基础上做修改，结果GG了，更悲催的是忘了改了什么地方…</p>
<p>也许你可以通过不断“save as”来解决，但是久而久之，你的文件会变得非常凌乱。对于少量文件或许行得通，但是一涉及包含大量文件的项目。光整理文件就足以让人头痛:-(</p>
<p>这个时候你就需要有一个版本管理工具来辅助你完成这些恼人且琐碎的工作，没错，它就是git。不要怕，git只是一个版本管理工具罢了，我们只需要学习如何使用它。</p>
<p><img src="http://ww4.sinaimg.cn/bmiddle/9150e4e5gy1fssxfpndxhj20hq0d0t95.jpg" alt="img" style="zoom: 33%;" /></p>
<h3 id="1-1-git能干什么"><a href="#1-1-git能干什么" class="headerlink" title="1.1 git能干什么"></a>1.1 git能干什么</h3><p>   git功能很强大，它可以：</p>
<ul>
<li>帮助你管理不同的代码版本<ul>
<li>代码存档，读档，就像玩游戏一样方便</li>
<li>在不改变原有代码的基础上，同时开发不同版本代码，听起来很魔法对吧~</li>
<li>结合远程服务器(这里是github)，本地代码丢失也不怕！</li>
</ul>
</li>
<li>多人协同开发，也可以使自己的笔记本和台式机之间协同。</li>
</ul>
<h3 id="1-2-github是什么"><a href="#1-2-github是什么" class="headerlink" title="1.2 github是什么"></a>1.2 github是什么</h3><p> github我们多少已经熟悉了，知道它是全球最大的<del>同性交友网站</del>开源社区。这篇文档中我们主要是为了使用它的仓库（respositories）功能。我们只需要简单把仓库理解为一个远程的存储服务器就好了，就像百度云或Onedrive之类的。</p>
<blockquote>
<p>你可能不理解大家为什么要公开自己的代码。开源是一种精神，大家去分享自己的智慧，解放生产力，避免重复造轮子。其实早先github上只有公开仓库是免费的，直到财大气粗的微软爸爸收购github之后，github才提供四人以下的免费私人仓库。</p>
</blockquote>
<h2 id="2-准备"><a href="#2-准备" class="headerlink" title="2.准备"></a>2.准备</h2><p>现在我们知道了：</p>
<ul>
<li>git是一个版本管理工具，用于管理你的代码</li>
<li>github是一个远程仓库，用于远程保管你的代码以及多人协同工作</li>
</ul>
<p>那么我们在学习git之前需要一些准备，我们需要：</p>
<ul>
<li><p>一个github账号</p>
</li>
<li><p>git客户端，windows下直接去<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">官方网站</a>下载git.exe就好啦</p>
</li>
<li><p>vscode</p>
<blockquote>
<p>git涉及到一些命令行操作, 不过请不要害怕, 只需要掌握几条简单的命令就可以帮助我们熟练的使用git。这篇文档也会尽量简单并且图文并茂的讲述每条命令的使用方式。</p>
<p>如果你还是不能接受，也请看完第三章，理解整个工作流程后使用VScode无代码化的使用git。</p>
</blockquote>
</li>
</ul>
<h3 id="2-1-git的安装"><a href="#2-1-git的安装" class="headerlink" title="2.1 git的安装"></a>2.1 git的安装</h3><p>只有一点需要注意，在执行到这一步时需要选择使用其它编辑器(比如vscode)作为git的默认编辑器，当然如果你能够灵活的使用vim也可以选择vim作为默认编辑器。其他的一路ok就好！</p>
<p><img src="https://i.loli.net/2020/06/17/Mwz5VB1eg2CSbLx.png" alt="1574419008585"></p>
<p><img src="https://i.loli.net/2020/06/17/rTeE3d1YgBmypHi.png" alt="1574419098015"></p>
<p>打开git bash，输入以下命令完成注册：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name "user.name" #你的用户名</span><br><span class="line">git config --global user.email "yourmail@youremail.com.cn" #你的邮箱</span><br></pre></td></tr></table></figure>
<p>新建ssh keys，没有ssh keys无法上传文件到github。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C "你的邮箱名" #新建ssh keys</span><br></pre></td></tr></table></figure>
<p>你可以指定ssh keys的存放路径，下图第一个是默认路径，第二个箭头是你的指定。不指定直接回车就是默认路径。</p>
<p><img src="https://i.loli.net/2020/06/17/qiM3fXQNLCOpm7G.png" alt="1574570114514"></p>
<p> 然后找到rd_rsa和id_rsa.pub所在目录打开idb_rsa.pub,登录自己的GitHub账号，找到Settings,</p>
<p><img src="https://i.loli.net/2020/06/17/hcPfLu1wIak3egD.png" alt="1574570638254"></p>
<p><img src="https://i.loli.net/2020/06/17/qQybxAPdG7S34HZ.png" alt="image-20200617142820627"></p>
<p><img src="https://i.loli.net/2020/06/18/celnpDAWbF9ztoX.png" alt="1574570467035"></p>
<p> 然后，将idb_rsa.pub里的内容拷贝到Key内，Title内容随便填，确定即可。 </p>
<p><img src="https://i.loli.net/2020/06/17/7tOu1S9nNhXvETR.png" alt="image-20200617142909156"></p>
<p>添加完成。。</p>
<h2 id="3-git使用教程"><a href="#3-git使用教程" class="headerlink" title="3.git使用教程"></a>3.git使用教程</h2><h3 id="3-1-建立版本仓库"><a href="#3-1-建立版本仓库" class="headerlink" title="3.1 建立版本仓库"></a>3.1 建立版本仓库</h3><p>在介绍github时我们提到了仓库，其实仓库就是你用于存放代码的文件夹，放在远程服务器的叫做<strong>远端仓库</strong>(简称远端)，放在自己电脑上的叫做<strong>本地仓库</strong>(简称本地)。</p>
<h4 id="3-1-1-建立本地仓库"><a href="#3-1-1-建立本地仓库" class="headerlink" title="3.1.1  建立本地仓库"></a>3.1.1  建立本地仓库</h4><ol>
<li><p>新建一个文件夹（这里我新建了Code），或者是打开存放有你自己项目的文件夹，<strong>注意，不能包含中文路径</strong>。</p>
</li>
<li><p>在文件夹中右键，点击Git Bash Here。当然你也可以在任意地方打开Git bash然后使用cd命令进入你想要去的文件夹。</p>
<p><img src="https://i.loli.net/2020/06/17/JDi6pWLjRSBgrOc.png" alt="1574420614404"></p>
</li>
<li><p>在打开的git bash中输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git init #这条命令代表在当前文件夹下建立一个版本仓库</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/ri5eG9jagDJP4TB.png" alt="1574474899359"></p>
<p>如果看到文件夹下多出了一个.git文件（默认隐藏，你可能要在“查看”里打开查看隐藏文件才能看到）就说明版本仓库建立成功。这个文件是git用于管理版本的，我们不用去管它。git bash中路径的后面还出现了一个”(master)”，这是你的版本库所在的当前分支。</p>
<p>现在Code文件夹已经从一个普通的文件夹变成了我们的仓库。</p>
</li>
</ol>
<h4 id="3-1-2-在github中建立仓库"><a href="#3-1-2-在github中建立仓库" class="headerlink" title="3.1.2 在github中建立仓库"></a>3.1.2 在github中建立仓库</h4><p>经验告诉我们，我们的计算机是不可靠的，死机、误删、磁盘坏道、重装系统，这一切你想得到想不到的问题都可能导致我们用于交差的东西毁于一旦。</p>
<p>我们当然可以用网盘或者U盘即使备份，但是有github这样简单、免费又好用的工具，只要几步，我们就可以在github上建立自己的远程仓库！</p>
<ol>
<li><p>登录github，在主页左上角点击NEW，新建一个respository</p>
<p><img src="https://i.loli.net/2020/06/17/gAvnx9QBF6Mycmt.png" alt="1574477727084"></p>
</li>
<li><p>指明以下信息：</p>
<ul>
<li><p>仓库的名字</p>
</li>
<li><p>仓库的描述</p>
</li>
<li><p>仓库的类型</p>
<ul>
<li>公开：所有人都能看到你的仓库，别人可以在你的仓库上建立分支，修改你的代码以及进行提交，由你来决定是否接收他人的提交</li>
<li>私人：你可以选择最多3个人(现在已经不限人数)，只有被你选召的孩子可以执行上述操作，他们的提交不需要你同意！</li>
</ul>
</li>
<li><p>是否要在新建仓库的同时建立一个readme文件</p>
<ul>
<li><p>强烈建议不要勾选，很坑。代码一般存放在本地，勾选后远端就会出现一个你本地没有的文件，这会造成冲突！</p>
<p><img src="https://i.loli.net/2020/06/17/3oUlsubapIBq1xj.png" alt="1574479176608"></p>
</li>
</ul>
</li>
<li><p>是否增加.gitignore和license</p>
<ul>
<li>同样建议不要选，理由同上。</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/06/17/zxI3TCtaluo7w2y.png" alt="1574477683881"  /></p>
</li>
</ol>
<h3 id="3-2-提交自己的代码"><a href="#3-2-提交自己的代码" class="headerlink" title="3.2 提交自己的代码"></a>3.2 提交自己的代码</h3><h4 id="3-2-1-工作区，暂存区和版本库"><a href="#3-2-1-工作区，暂存区和版本库" class="headerlink" title="3.2.1 工作区，暂存区和版本库"></a>3.2.1 工作区，暂存区和版本库</h4><p>仓库建立好后我们的就可以正式开始工作了，Code文件夹下的文档变动都会被git察觉。假设我们在Code文件夹下写好或者拷贝了一个文件“12345.txt”，让我们输入下面的命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git status #查看工作区状态</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/8VOE21dMe45ABSi.png" alt="1574498025597"></p>
<p><img src="https://i.loli.net/2020/06/17/eva8cjkVDtnpJGB.png" alt="1574480666077"></p>
<p>提示我们有一个未跟踪的文件“12345.txt”，这是什么意思呢？想要git管理我们的代码我们就必须先提交它，提交是分两步实现的。一是把文件加入到暂存区，二是把暂存区的文件提交到版本库。</p>
<p><img src="https://i.loli.net/2020/06/17/HhrxSRg3jdn6BOq.png" alt="1574496386379"></p>
<ul>
<li><p>工作区：是你真正正在修改、使用的文件</p>
</li>
<li><p>暂存区：存放你要提交的文件</p>
</li>
<li><p>版本库：存放代码的不同版本，相当于你代码的档案室</p>
</li>
</ul>
<h4 id="3-2-2-暂存文件"><a href="#3-2-2-暂存文件" class="headerlink" title="3.2.2 暂存文件"></a>3.2.2 暂存文件</h4><p>因为我们尽量希望自己的版本都是干净的代码，所以暂存和提交有必要分开，否则会造成版本过多，管理混乱。暂存文件的命令是</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add [文件名] #加入某个文件到暂存区</span><br><span class="line">或</span><br><span class="line">git add . # . 不可省略， 默认为将修改操作的文件和未跟踪新添加的文件添加到git系统的暂存区，注意不包括删除</span><br><span class="line">git add -A . #-A 表示将所有的已跟踪的文件的修改与删除和新增的未跟踪的文件都添加到暂存区</span><br></pre></td></tr></table></figure>
<p>让我们试一下，发现12345.txt被成功暂存了！</p>
<p><img src="https://i.loli.net/2020/06/17/Hn4SzvistFjMTJr.png" alt="1574496897728"></p>
<p>我们删掉它，用”add .” 试试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git rm --cached 12345.txt #rm表示移除 --cached表示缓存区的，所以这条命令指删除缓存区中的12345.txt</span><br><span class="line"><span class="meta">#</span><span class="bash">不常用的命令，毕竟修改文件后直接add就可以更新</span></span><br></pre></td></tr></table></figure>
<p>然后</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git add . #这条命令更常用，毕竟我们不能一个个的指定修改的文件吧</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/WCguehGZxJt4c7k.png" alt="1574497811333"></p>
<p>大功告成！</p>
<blockquote>
<p>建议经常使用add命令stage自己的代码，如果你修改了代码但是不stage是无法提交的。</p>
</blockquote>
<h4 id="3-2-3-存档和读档——后悔药"><a href="#3-2-3-存档和读档——后悔药" class="headerlink" title="3.2.3 存档和读档——后悔药"></a>3.2.3 存档和读档——后悔药</h4><p><strong>1.提交</strong></p>
<p>让我们修改文件再试试，这里我在12345.txt中加入了一行代码，并新增加了一个文件。</p>
<p><img src="https://i.loli.net/2020/06/17/ORICuv5i1Y7kb6V.png" alt="1574498426812"></p>
<p><img src="https://i.loli.net/2020/06/17/lBQfqo9RbmZdDpv.png" alt="1574498820234"></p>
<p>这些文件变动都被追踪到了。</p>
<p><img src="https://i.loli.net/2020/06/17/jlBga1dPhtv7ACm.png" alt="1574498714119"></p>
<p>想象自己是在玩游戏，如果我们进入到某个重要节点例如即将进入Boss战，我们通常都会及时存档以免自己损失惨重。同样写代码也该及时“存档”。输入commit(提交)命令进行提交，可见git知道我们提交了两个文件，增加了一行代码！</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git commit -m "版本说明" </span><br><span class="line"><span class="meta">#</span><span class="bash">双引号是提交代码时必须的说明，这是强制的，不写就无法提交</span></span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/Gxy5iqTnU7IZrAc.png" alt="1574499410230"></p>
<p>修改文件这两个文件再提交一次！</p>
<p><img src="https://i.loli.net/2020/06/17/UOL8reAQgnPamt9.png" alt="1574499977077"  /></p>
<p><img src="https://i.loli.net/2020/06/17/yAHYVovs51nhk8M.png" alt="1574500001341"></p>
<p><img src="https://i.loli.net/2020/06/17/Yu1b6DzZgyOARmE.png" alt="1574500348047"></p>
<p>输入git log以查看版本，箭头指向的是commit的版本号，我们可以用它回到任一版本。带有HEAD标志的就是当前版本库中存放的版本。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log #查看版本日志</span><br><span class="line">git log --graph ##以树状图的形式查看版本日志</span><br></pre></td></tr></table></figure>
<p><strong>2.回退版本</strong></p>
<p>假如我刚刚的代码出现了无法修复的重大bug怎么办？别担心，我们可以随时回退到之前的任意版本，因为我们存档了！</p>
<p>如果我们只是在工作区更改，还没有提交，比如我刚刚加入了一堆bug，试下这条命令就变回来了，很方便吧！这也是为什么我们要常常stage我们的文件。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -- [文件名] #将工作区文件状态恢复成最新的一次commit或者add的状态（取决于最后一次操作）</span><br><span class="line">git checkout -- .    	#撤销对所有文件的更改</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/HVopLJ1muArxisg.png" alt="image-20200617143345272" style="zoom: 67%;" /></p>
<p><img src="https://i.loli.net/2020/06/17/FuKEev8dk1CSrqX.png" alt="1574501873507"></p>
<p><img src="https://i.loli.net/2020/06/17/KX9dmilMBvJz71k.png" alt="1574501778180" style="zoom:80%;" /></p>
<p>如果我们已经把更改暂存甚至提交了，可以用reset命令回退到工作区，然后再使用checkout撤销更改</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reset HEAD [文件名] #将某个文件回退到最近一次提交，记得吧，HEAD表示当前版本</span><br><span class="line">git reset HEAD 	       #省略文件名表示回退所有文件</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/hZ9aVJT8l4sWX3O.png" alt="1574516044571"></p>
<p>如果我们觉得整个版本都不想要，就是想回某一个版本，还记的commit会出现一个版本号对吧，我们会用到的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reset --hard HEAD^ #一个^表示回到上一个版本</span><br><span class="line">git reset --hard HEAD^^#两个^表示回退一个版本</span><br><span class="line">git reset --hard [版本号，前5位就够了]#回退到版本号指定的版本</span><br></pre></td></tr></table></figure>
<p>我们先用git log看一下现在HEAD指向我们的第二次提交，回退一个版本后指向了第一次提交</p>
<p><img src="https://i.loli.net/2020/06/17/CDTH4bvNIgmiu75.png" alt="1574516513801"></p>
<p>再看看我们的文件，变回来了呢。</p>
<p><img src="https://i.loli.net/2020/06/17/SVm97FYteGN4Pcf.png" alt="1574516729966"></p>
<p>这时细心的你发现了，git log里没有第二次的版本号了，我又双叒叕反悔了怎么办，不要紧可以reflog一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reflog #查看历史命令，可以看到回退之前的版本号</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/P7y3OfWUEb4wjFI.png" alt="1574516864487"></p>
<p>版本号就回来啦！我们重新回到第二个版本，使用版本号“回退”一次 </p>
<p><img src="https://i.loli.net/2020/06/17/OZJPGd3rKwxD2ea.png" alt="1574517009092"></p>
<p>存档读档，妈妈再也不用担心我打不过boss了！</p>
<p>建议多用add暂存你的文件，在有关键更改时才提交，避免回退时面对茫茫多的版本不知所措。</p>
<h3 id="3-3-分支"><a href="#3-3-分支" class="headerlink" title="3.3  分支"></a>3.3  分支</h3><p>就算有了版本管理，老是回退版本也不是办法，别人总在你的版本上做更改也不方便。有没有我们一边开发一边还不影响已经稳定的版本的办法呢?git 给了这个机会，这就是分支。</p>
<p>记得我们新建仓库后路径后多出了一个master吧，这个就是git生成的默认分支，我们把它理解为树的主干。枝叶在主干上成长，树木的枝叶可以有很多，但是主干只能有一个。我们的开发应该是在枝叶上完成的。枝叶的生长不应该影响我们的主干。</p>
<p><img src="https://i.loli.net/2020/06/17/FBW9uVM7PQJivRs.png" alt="1574517843101"></p>
<p>在开发项目时我们要遵循以下几个原则：</p>
<ul>
<li>master分支只能是稳定的版本</li>
<li>分支可以尽量多，每个分支的功能应该明确</li>
<li>严禁在master分支上开发，应该在其他分支开发，修复bug，最后合并到master上</li>
</ul>
<h4 id="3-3-1-建立分支"><a href="#3-3-1-建立分支" class="headerlink" title="3.3.1 建立分支"></a>3.3.1 建立分支</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch [分支名] #新建分支</span><br><span class="line">git checkout [分支名] #切换到某一分支，注意撤销操作是checkout --，不加--就是切换分支</span><br><span class="line">git switch [分支名] #等价于上一条，建议用switch，更好理解</span><br></pre></td></tr></table></figure>
<p>下面的例子我新建了dev分支，然后使用switch而不是checkout进行切换</p>
<p><img src="https://i.loli.net/2020/06/17/2suFb41jwLfPJoi.png" alt="1574518245023"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -b [分支名] #新建分支并转到该分支</span><br><span class="line"><span class="meta">#</span><span class="bash">相当于一次执行下面两条命令</span></span><br><span class="line">git branch [分支名]</span><br><span class="line">git checkout [分支名]</span><br></pre></td></tr></table></figure>
<p>现在我们在刚刚的新建的进行开发，这里我修改12345.txt中的文件内容并且新建了develop.txt，然后提交</p>
<p><img src="https://i.loli.net/2020/06/17/oNvgLkrqlSJ95bh.png" alt="1574561916685"></p>
<p><img src="https://i.loli.net/2020/06/17/dFzTkqhPrfLjn1v.png" alt="1574562000782"></p>
<p>切回master分支看一下</p>
<p><img src="https://i.loli.net/2020/06/17/qHtGKN1pbURMcey.png" alt="1574562220417"></p>
<p>可以看到master分支下12345.txt并没有收到改变，这样我们就可以在不影响原有代码的基础上进行开发。</p>
<p><img src="https://i.loli.net/2020/06/17/yZwBFKDTlvmHbfS.png" alt="1574562249277"></p>
<h4 id="3-3-1-合并分支"><a href="#3-3-1-合并分支" class="headerlink" title="3.3.1 合并分支"></a>3.3.1 合并分支</h4><p>如果我们在dev分支上的开发已经稳定，认为可以将master前进一个版本，我们就可以使用merge命令进行分支合并。首先我们要切换到master分支。然后使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git merge dev #将dev合并到当前分支上，这里的dev可以是任意分支名</span><br></pre></td></tr></table></figure>
<p>再看看master分支下的内容，已经和dev分支一样了。</p>
<p><img src="https://i.loli.net/2020/06/17/UBJsYFMrTnbhqZz.png" alt="1574563214269"></p>
<p><img src="https://i.loli.net/2020/06/17/dRmPjXo5VkpiSnz.png" alt="1574563395685"></p>
<p>因为我们的dev分支是在master的基础上前进了一步，所以合并时没有冲突。但是如果我在开发dev的同时手贱更改了master中的内容，又该怎么办呢？这就涉及到冲突的解决。</p>
<p><img src="https://i.loli.net/2020/06/17/A8TxCsXb4VRMI2z.png" alt="1574564519494"></p>
<p><img src="https://i.loli.net/2020/06/17/CLcHF7hpJPRU4lT.png" alt="1574564562140"></p>
<h4 id="3-3-2-解决冲突"><a href="#3-3-2-解决冲突" class="headerlink" title="3.3.2 解决冲突"></a>3.3.2 解决冲突</h4><blockquote>
<p>冲突在个人开发时很少遇到，你可以酌情先跳过本节。</p>
</blockquote>
<p>我们更改master分支下develop.txt的内容如下，然后提交：</p>
<p><img src="https://i.loli.net/2020/06/17/bLCoMp4tZmEU2ux.png" alt="1574563921647"></p>
<p>切换到dev分之下修改develop.txt的内容如下，然后提交：</p>
<p><img src="https://i.loli.net/2020/06/17/896bt1VieT3JnOx.png" alt="1574564171623"></p>
<p>再试试吧dev上的内容合并到master上，结果出错了。</p>
<p><img src="https://i.loli.net/2020/06/17/2JigvsomXGRNKYO.png" alt="1574564284348"></p>
<p>因为master和dev同时前进了一步，对相同的文件做了不同修改，git不知道哪个修改是你要的，只好提示你手动修改。不过你放心，git只会比较文件中不同的地方，如果你没用在同一处做了不一样的改动，是不会引起冲突的。</p>
<p><img src="https://i.loli.net/2020/06/17/YNxWXoJrzIdZkbj.png" alt="1574564467758"></p>
<p>我们看一下develop.txt，git已经帮我们标记出了冲突的地方。</p>
<blockquote>
<p>这里是用vscode打开的，你也可以用其他工具，例如更加强大的visual stuido，或者更挫的记事本。用vscode只是因为它轻量而且方便，足够我们使用。</p>
</blockquote>
<p><img src="https://i.loli.net/2020/06/17/BoMFCkY2ptewyuR.png" alt="1574565354909"></p>
<p>我们们只需要更改自己想要的代码，然后点击采用当前或者传入的更改问题就解决了！</p>
<p><img src="https://i.loli.net/2020/06/17/jwZki4p8XJTLBo1.png" alt="1574565759381"></p>
<p><img src="https://i.loli.net/2020/06/17/YgPBKkiC6bmwUlR.png" alt="1574565786283"></p>
<p>然后提交，ok冲突解决了！</p>
<p><img src="https://i.loli.net/2020/06/17/v7FWcwmJLIBsfV6.png" alt="1574566655509"></p>
<h3 id="3-4-同步代码到github"><a href="#3-4-同步代码到github" class="headerlink" title="3.4 同步代码到github"></a>3.4 同步代码到github</h3><p>虽然只在本地使用git已经足够方便，但是结合github或者其他服务器进行多人或者多设备开发才是git的完全体。</p>
<h4 id="3-4-1-关联本地到远端"><a href="#3-4-1-关联本地到远端" class="headerlink" title="3.4.1 关联本地到远端"></a>3.4.1 关联本地到远端</h4><p>在github中找到我们在3.1.2中建立的仓库，复制地址</p>
<p><img src="https://i.loli.net/2020/06/17/tqahvODxyC4gwFf.png" alt="1574570751233"></p>
<p>在本地的git bash中输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin git@github.com:shawer96/Code.git #origin是默认的远程主机名，后面的地址应该填你自己刚刚复制的</span><br></pre></td></tr></table></figure>
<h4 id="3-4-2-推送代码到远端"><a href="#3-4-2-推送代码到远端" class="headerlink" title="3.4.2 推送代码到远端"></a>3.4.2 推送代码到远端</h4><p>推送是指将你的代码上传到远端，以便其他设备或者他人下载使用。</p>
<p>我们之前在git上建立了一个空仓库，可以使用下述命令进行提交</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push -u origin master #-u表示在远端建立一个同名分支（因为远端是空的），master可以换成其他你想推送的分支</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/AmboLpfR98FZXxe.png" alt="1574572578570"></p>
<p><img src="https://i.loli.net/2020/06/17/CTD4auMtQI96XPc.png" alt="1574574475359"></p>
<p>之后想要在master分支上提交其他内容就不需要-u了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push origin 本地分支名：远端分支名 #将本地分支推送到远端分支</span><br><span class="line">git push origin 本地分支名  #省略远端分支名(常见)，将本地分支推送到远端同名分支</span><br></pre></td></tr></table></figure>
<h4 id="3-4-3-拉去代码到本地"><a href="#3-4-3-拉去代码到本地" class="headerlink" title="3.4.3 拉去代码到本地"></a>3.4.3 拉去代码到本地</h4><p>有的时候我们在别的设备上完成开发，并且推送到了远端，你想要下载代码到本地。只需要使用pull命令，比如我现在在github的网页上修改了12345.txt来模拟多设备或者多人的开发情况。</p>
<p><img src="https://i.loli.net/2020/06/17/fBp5LogQalNCmRy.png" alt="1574575282941"></p>
<p>只要使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull origin 远端分支名:本地分支名 #将本地分支拉取到远端分支</span><br><span class="line">git pull origin 远端分支名 #省略本地分支名(常见)，将远端分支拉取到本地同名分支</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/06/17/nLaAyTmOjv1xhCk.png" alt="1574575535115"></p>
<p><img src="https://i.loli.net/2020/06/17/pDLrzG2Col4MaUw.png" alt="1574576045808"></p>
<p>要注意，拉取其实相当于将远端分支取回到本地暂存区，再合并到本地分支。所以在远端和本地文件不同时也会出现冲突，可以按照3.3.2中的方法解决。</p>
<h2 id="4-Vscode使用git"><a href="#4-Vscode使用git" class="headerlink" title="4. Vscode使用git"></a>4. Vscode使用git</h2><ol>
<li><p>选择文件-&gt;打开-&gt;打卡文件夹，打开你设为git仓库的文件夹</p>
<p><img src="https://i.loli.net/2020/06/17/UAtIsbjF3SzMfwE.png" alt="1574576153117"></p>
</li>
<li><p>点击左侧的按钮</p>
<p><img src="https://i.loli.net/2020/06/17/x2V4YeINv5jzDEZ.png" alt="1574576231294"></p>
</li>
<li><p>可以看到工作区中修改过的文件</p>
<p><img src="https://i.loli.net/2020/06/17/CRzGlV2vm5xPakK.png" alt="1574576326763"></p>
</li>
<li><p>右键可以选择对文件执行哪些操作</p>
<p><img src="https://i.loli.net/2020/06/17/myuTdiPZRBgMAe5.png" alt="1574576394125"></p>
<ul>
<li><p>打开更改：比较工作区文件和暂存区区别，如上图，很方便的功能</p>
</li>
<li><p>暂存(stage)，相当于add</p>
</li>
</ul>
</li>
<li><p>暂存后可以选择提交</p>
<p><img src="https://i.loli.net/2020/06/17/moqYW7Tvfzr1KDF.png" alt="1574576520054"></p>
<p><img src="https://i.loli.net/2020/06/17/PTWoVJLI6hcaKX5.png" alt="1574576685215"></p>
<p>看看日志，提交成功了</p>
<p><img src="https://i.loli.net/2020/06/17/v8yxGWstq7R29FS.png" alt="1574576749510"></p>
</li>
<li><p>还有更多功能自己去试试吧</p>
<p><img src="https://i.loli.net/2020/06/17/onE8FMQGW4TbuVN.png" alt="1574576891330"></p>
</li>
</ol>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote>
<p><a href="https://www.liaoxuefeng.com/wiki/896043488029600" target="_blank" rel="noopener">git教程—廖雪峰</a></p>
</blockquote>
]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>散列表查找(哈希表)概述</title>
    <url>/2020/06/24/3_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%A3%E5%88%97%E8%A1%A8%E6%9F%A5%E6%89%BE-%E5%93%88%E5%B8%8C%E8%A1%A8-%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="散列表-Hash表"><a href="#散列表-Hash表" class="headerlink" title="散列表(Hash表)"></a>散列表(Hash表)</h1><h2 id="1-Hash表查找定义"><a href="#1-Hash表查找定义" class="headerlink" title="1. Hash表查找定义"></a>1. Hash表查找定义</h2><ul>
<li><p>散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f, 是的每个关键字key对应一个存储位置 f(key).</p>
</li>
<li><p>查找时, 根据这个确定的对应关系找到给定key值对应的映射 f(key), 若在查找集合中存在这个记录, 则必定在f(key)的位置上.</p>
</li>
<li>我们把这种对应关系 f 称为<strong>散列函数</strong>, 又称<strong>哈希(Hash)函数</strong>. 采用散列技术将记录存储在一块连续的存储空间中, 这块连续的存储空间称为<strong>散列表</strong>或者<strong>哈希表(Hash table)</strong>.</li>
</ul>
<h2 id="2-查找步骤"><a href="#2-查找步骤" class="headerlink" title="2. 查找步骤"></a>2. 查找步骤</h2><a id="more"></a>
<ol>
<li><p>存储时: 通过散列函数计算记录的散列地址, 并按此散列地址存储该记录(先计算地址再储存)</p>
<p><img src="https://i.loli.net/2020/06/28/3MieavkfDp8J7Wb.png" alt="image-20200628155831116"></p>
</li>
<li><p>查找记录时: 通过同样的散列函数计算记录的散列地址, 按此散列地址访问该记录</p>
</li>
</ol>
<p>散列技术既是一种存储方法, 又是一种查找方法. 散列的记录之间不存在什么逻辑关系, 它只与关键字有关.<strong>散列技术最适合的求解问题是查找与给定值相等的记录.</strong></p>
<p>拥有同样关键字但是对应多重记录情况的不适合使用散列.比如利用性别查找一个学生, 相反, 利用学号或者身份证号来散列存储才比较合适.</p>
<h2 id="3-构造方法"><a href="#3-构造方法" class="headerlink" title="3. 构造方法"></a>3. 构造方法</h2><p><strong>原则</strong></p>
<ol>
<li><p>计算简单</p>
<p>散列函数的计算时间不应该超过其他查找技术和关键字比对时间</p>
</li>
<li><p>地址均匀分布</p>
</li>
</ol>
<h3 id="3-1-直接定址法"><a href="#3-1-直接定址法" class="headerlink" title="3.1 直接定址法"></a>3.1 直接定址法</h3><p>取关键字的某个线性函数作为散列地址, 即</p>
<script type="math/tex; mode=display">
f(key)=a\times key +b</script><p>比如统计80年后出生年份人口数, 可以对出生年份这个关键字减去1980此时<code>f(key)=key-1980</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>地址</th>
<th>出生年份</th>
<th>人口</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>1980</td>
<td>1500万</td>
</tr>
<tr>
<td>01</td>
<td>1981</td>
<td>1600万</td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>优点是简单均匀不产生冲突, 但是需要预先知道关键字分布情况, 只适合查找表较小且连续的情况.</p>
<h3 id="3-2-数字分析法"><a href="#3-2-数字分析法" class="headerlink" title="3.2 数字分析法"></a>3.2 数字分析法</h3><p>如果关键字位数较多, 可以<strong>抽取(使用关键字的一部分)</strong>其中某几位数字, 比如手机号的后四位. 可以对抽取的数字进行翻转, 右环位移, 左环位移等方法避免冲突.</p>
<p>适合于关键字数字较大的情况, 如果知道关键字分布情况而且若干位分布均匀可以用此方法. </p>
<h3 id="3-3-平方取中法"><a href="#3-3-平方取中法" class="headerlink" title="3.3 平方取中法"></a>3.3 平方取中法</h3><p>如, 关键字是1234, 平方就是1522756, 取中间三位为227, 用作散列地址.</p>
<p>适合于不知道关键字分布, 位数也不是很大的方法.</p>
<h3 id="3-4-折叠法"><a href="#3-4-折叠法" class="headerlink" title="3.4 折叠法"></a>3.4 折叠法</h3><p>将关键字左右分割为相等的几部分, 将这几部分叠加求和, 按照散列表表长, 取最后几位作为地址.</p>
<p>如9876543210, 987+654+321+0=1962, 以962作为地址.</p>
<p>为保证分布均匀也可以将一端反转后再相加如789+654+123+0=1566, 此时散列地址为566.</p>
<p>适合关键字较长的情况.</p>
<h3 id="3-5-除留余数法"><a href="#3-5-除留余数法" class="headerlink" title="3.5 除留余数法"></a>3.5 除留余数法</h3><p>对于散列表长度为m的散列函数公式为：</p>
<script type="math/tex; mode=display">
f(key)=key \ mod \ p (p\leq m)</script><p>例如下表, 采用<code>f(key) = key mod 12</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>关键字</th>
<th>12</th>
<th>25</th>
<th>38</th>
<th>15</th>
<th>16</th>
<th>29</th>
<th>78</th>
<th>67</th>
<th>56</th>
<th>21</th>
<th>22</th>
</tr>
</thead>
<tbody>
<tr>
<td>下标</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-6-随机数法"><a href="#3-6-随机数法" class="headerlink" title="3.6 随机数法"></a>3.6 随机数法</h3><p>取关键字的随机函数作为它的散列地址:</p>
<script type="math/tex; mode=display">
f(key)=random(key)</script><p>实际中应该视不同情况采用不同的散列函数, 可以考虑以下因素:</p>
<ol>
<li>计算散列地址所需时间</li>
<li>关键字的长度</li>
<li>散列表的大小</li>
<li>关键字的分布情况</li>
<li>记录的查找频率</li>
</ol>
<h2 id="4-处理散列冲突的方法"><a href="#4-处理散列冲突的方法" class="headerlink" title="4. 处理散列冲突的方法"></a>4. 处理散列冲突的方法</h2><p><strong>散列冲突:</strong> 对于关键字 <code>key1!= key2</code>, 却有 <code>f(key1) = f(key2)</code></p>
<h3 id="4-1-开放定址法"><a href="#4-1-开放定址法" class="headerlink" title="4.1 开放定址法"></a>4.1 开放定址法</h3><p>开放定址法是指一旦发生了冲突, 就去寻找下一个空的散列地址, 只要散列表足够大, 空的散列地址总能找到.</p>
<p>公式是:</p>
<script type="math/tex; mode=display">
f_i(key)=(f(key)+d_i)\ MOD\  m \ (d_i=1,2,3,\ldots,m-1)</script><p>比如我们采用散列函数<code>f(key)=key mod 12</code>可以发现f(25)=1, 当key=37时就出现了冲突, 于是依照上面的公式有<code>f(37)=(f(37)+1) mod12=2</code>.</p>
<p>假如key=48也发生了冲突, 那么按上述公式应该为<code>f(48)=(f(48)+1) mod12=1</code>, 这又和25所在位置冲突, 于是<code>f(48)=(f(48)+2) mod12=2</code>, 还是冲突, 一直到<code>f(48)=(f(48)+3) mod12=3</code>, 才出现空位.</p>
<p>上述这种解决办法<strong>称为线性探索法.</strong> 像48和37这种本来不是同义词却要争夺相同地址的情况称为<strong>堆积</strong>.</p>
<p>为了避免关键词都聚集在某一区域, 可以对上述公式进行优化, 增加平方运算来改进di:</p>
<script type="math/tex; mode=display">
f_i(key)=(f(key)+d_i)\ MOD\  m\  (d_i=1^2,(-1)^2,2^2,(-2)^2,\ldots,q^2,(-q)^2, q\leq m/2)</script><p>这种方法称为 <strong>二次探测法</strong>.</p>
<p>还有一种解决办法是, 对于位移量di采用随机函数得到, 称为随机探测法:</p>
<script type="math/tex; mode=display">
f_i(key)=(f(key)+d_i)\ MOD\  m \ (d_i是一个随机数列)</script><h3 id="4-2-再散列函数法"><a href="#4-2-再散列函数法" class="headerlink" title="4.2 再散列函数法"></a>4.2 再散列函数法</h3><script type="math/tex; mode=display">
f_i(key)=RH_i(key)\ (i=1,2,3,\dots,k)</script><p>事先准备多个散列函数, 这里的$RH_i$就是不同的散列函数, 每当发生散列冲突就换一个散列计算函数, 当然也相应的增加了计算时间.</p>
<h3 id="4-3-链地址法"><a href="#4-3-链地址法" class="headerlink" title="4.3 链地址法"></a>4.3 链地址法</h3><p>不需要冲突换址, 将所有关键词的同义词记录在一个单链表中,称为, 同义词表, 在哈希表中只存储同义词表的头指针. 无论有多少冲突, 都这是在当前位置给单链表增加节点.</p>
<p>在哈希表每一个单元中设置链表，某个数据项对的关键字还是像通常一样映射到哈希表的单元中，而数据项本身插入到单元的链表中。简单理解如下：</p>
<p><img src="https://pic3.zhimg.com/v2-482e5ff497e9dc709d1c760bcff3c12e_r.jpg" alt="img"></p>
<p>优点为所有冲突提供了地址保障.</p>
<p>缺点是带来了查找时需要遍历单链表的性能损耗.</p>
<h3 id="4-4-公共溢出区法"><a href="#4-4-公共溢出区法" class="headerlink" title="4.4 公共溢出区法"></a>4.4 公共溢出区法</h3><p>为有冲突的关键字提供<strong>公共溢出区</strong>来存放.</p>
<p>在查找时对给定值通过散列函数计算散列地址后, 先与基本表对应位置进行对比, 如果相等则查找成果, 如果不相等则到溢出表去进行顺序查找.</p>
<h2 id="5-散列表查找实现"><a href="#5-散列表查找实现" class="headerlink" title="5. 散列表查找实现"></a>5. 散列表查找实现</h2><h3 id="5-1-代码"><a href="#5-1-代码" class="headerlink" title="5.1 代码"></a>5.1 代码</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SUCCESS 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> UNSUCCESS 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> HASH_SIZE 12</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NULL_KEY -32768</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hash</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">/* data */</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Hash();</span><br><span class="line">    ~Hash();</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">hashFunc</span><span class="params">(<span class="keyword">int</span> key)</span></span>; <span class="comment">//hash function</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insertHash</span><span class="params">(<span class="keyword">int</span> key)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">searchHash</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> *addr)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> *elemArr; <span class="comment">//数据存储元素基地址, 动态分配数组</span></span><br><span class="line">    <span class="keyword">int</span> count;    <span class="comment">//当前元素个数</span></span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">size</span>;     <span class="comment">//散列表长</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//initialize hash table</span></span><br><span class="line">Hash::Hash()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">size</span> = HASH_SIZE;</span><br><span class="line">    count = <span class="built_in">size</span>;</span><br><span class="line">    elemArr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="built_in">size</span>];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="built_in">size</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        elemArr[i] = NULL_KEY;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Hash::~Hash()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (elemArr != <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span>[] elemArr;</span><br><span class="line">        elemArr = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Hash::hashFunc</span><span class="params">(<span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> key % <span class="built_in">size</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Hash::insertHash</span><span class="params">(<span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> addr = hashFunc(key);</span><br><span class="line">    <span class="keyword">while</span> (elemArr[addr] != NULL_KEY)   <span class="comment">//不为空</span></span><br><span class="line">    &#123;</span><br><span class="line">        addr = (addr + <span class="number">1</span>) % <span class="built_in">size</span>;       <span class="comment">//线性探测</span></span><br><span class="line">    &#125;</span><br><span class="line">    elemArr[addr] = key;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Hash::searchHash</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> *addr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    *addr = hashFunc(key);          <span class="comment">//求散列地址</span></span><br><span class="line">    <span class="keyword">while</span> (elemArr[*addr] != key)   <span class="comment">//如果不为空, 则冲突</span></span><br><span class="line">    &#123;</span><br><span class="line">        *addr = (*addr + <span class="number">1</span>) % <span class="built_in">size</span>;</span><br><span class="line">        <span class="keyword">if</span> (elemArr[*addr] == NULL_KEY || *addr == hashFunc(key))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> UNSUCCESS;       <span class="comment">//如果循环回到原点则说明关键字不存在</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Hash Hash;</span><br><span class="line">    <span class="keyword">int</span> arr[HASH_SIZE] = &#123;<span class="number">12</span>, <span class="number">67</span>, <span class="number">56</span>, <span class="number">16</span>, <span class="number">25</span>, <span class="number">37</span>, <span class="number">22</span>, <span class="number">29</span>, <span class="number">15</span>, <span class="number">47</span>, <span class="number">48</span>, <span class="number">34</span>&#125;;</span><br><span class="line">    <span class="comment">// int len = sizeof(arr)/sizeof(int);</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; HASH_SIZE; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Hash.insertHash(arr[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; HASH_SIZE; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; Hash.elemArr[i] &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-2-性能分析"><a href="#5-2-性能分析" class="headerlink" title="5.2 性能分析"></a>5.2 性能分析</h3><p>如果没有冲突, 那么Hash表查找的时间复杂度为O(1), 但是冲突往往无法避免, 那么Hash查找的平均查找长度取决于:</p>
<ol>
<li>散列是否均匀, 不太影响.</li>
<li>处理冲突的方法, 线性探测冲突可能产生堆积, 链地址法不产生任何堆积. 因此后者平均性能更好. </li>
<li>Hash表的装填因子, $\alpha= $表中记录的个数/散列表长度. 越大越容易产生冲突. 通常设置Hash表空间比集合大, 以空间换时间.</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读笔记--Buffet</title>
    <url>/2020/06/12/5_%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-Buffet/</url>
    <content><![CDATA[<h1 id="Buffets-An-Efficient-and-Composable-Storage-Idiom-for-Explicit-Decoupled-Data-Orchestration"><a href="#Buffets-An-Efficient-and-Composable-Storage-Idiom-for-Explicit-Decoupled-Data-Orchestration" class="headerlink" title="Buffets: An Efficient and Composable Storage Idiom for Explicit Decoupled Data Orchestration"></a>Buffets: An Efficient and Composable Storage Idiom for Explicit Decoupled Data Orchestration</h1><blockquote>
<p>原文: Pellauer, M., et al. (2019). Buffets. Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS ‘19: 137-151.</p>
</blockquote>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="1-要解决什么问题"><a href="#1-要解决什么问题" class="headerlink" title="1. 要解决什么问题"></a>1. 要解决什么问题</h3><p>提出针对加速器不同需求通用的, 可重用的storage idiom, 它独立于任何特定的设计.</p>
<h3 id="2-通过什么理论或者模型来解决"><a href="#2-通过什么理论或者模型来解决" class="headerlink" title="2. 通过什么理论或者模型来解决"></a>2. 通过什么理论或者模型来解决</h3><ul>
<li><p>Buffet</p>
</li>
<li><p>Decoupled fills and accesses with fine-grained synchronization.</p>
</li>
<li><p>Hierarchical composition, and efficient multi-casting. </p>
</li>
</ul>
<h3 id="3-给出了什么答案"><a href="#3-给出了什么答案" class="headerlink" title="3. 给出了什么答案"></a>3. 给出了什么答案</h3><p>在8KB RAM上仅仅增加2%的控制开销,与DMA管理的double-buffer scratched pad和跨各种工作负载的cache相比，Buffet分别将能量延迟乘积提高了1.53倍和5.39倍。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="1-研究意义"><a href="#1-研究意义" class="headerlink" title="1. 研究意义"></a>1. 研究意义</h3><p>相较于通用芯片, 数据编排(data orchestration)—即将数据移入或者移出buffer heirarchy, 是专用加速芯片实现高性能的重要方法.</p>
<p><img src="https://i.loli.net/2020/06/11/4sbALD7TirONE19.png" alt="image-20200611104101471" style="zoom:80%;" /></p>
<p>加速器在定制的片上缓冲上花费了大量的精力。不幸的是，这些解决方案与特定设计紧密相关，从而妨碍了其他加速器领域的可重用性。</p>
<h3 id="2-研究背景"><a href="#2-研究背景" class="headerlink" title="2. 研究背景"></a>2. 研究背景</h3><p>Existing reusable buffer idiom:</p>
<p>cache</p>
<ul>
<li>过多面积和功耗用于隐式数据编排, 与加速器需求不一致.</li>
</ul>
<p>scratched pad</p>
<ul>
<li>不灵活, 不满足复杂数据重用和更新模式需求.</li>
</ul>
<p>FIFO</p>
<ul>
<li>缺乏同步性, 难以层次化..</li>
</ul>
<h3 id="3-基于哪些假设"><a href="#3-基于哪些假设" class="headerlink" title="3. 基于哪些假设"></a>3. 基于哪些假设</h3><ol>
<li>显式解耦合(EDDO)方式.</li>
<li>同步实现方式.</li>
<li>Buffet与层次化存储结合, buffet间同步, 支持单buffet多数据广播.</li>
</ol>
<h2 id="Classifying-Data-Orchestration"><a href="#Classifying-Data-Orchestration" class="headerlink" title="Classifying Data Orchestration"></a>Classifying Data Orchestration</h2><p>加速器架构师利用他们在设计时对工作负载特征和访问模式的了解，可以获得以下收益：</p>
<ul>
<li>预取—提前准确的取来将被使用的数据,</li>
<li>在最小，最快和最节能的缓冲区中最大程度地访问数据,</li>
<li><del>将数据暂存到层次结构中共享者之间最小上限的缓冲区中,</del></li>
<li>将下一个数据图块的填充与当前数据图块的消耗重叠，</li>
<li>同时向访问的数据的所有使用者广播（或multi-casting）缓冲区访问的结果，</li>
<li>精确且廉价地同步数据可用性,</li>
<li>准确删除不再需要的数据</li>
</ul>
<p>传统应用场景下的resuable buffering idioms分类:</p>
<p>​        implict/explict: workload在何种程度上决定暂存, 缓存策略.</p>
<p>​        coupled/decoupled: 访存请求是round-trip还是flow-forward.</p>
<p><img src="https://i.loli.net/2020/06/11/HG2x6trF9miWDl8.png" alt="image-20200611115419792" style="zoom: 67%;" /></p>
<h3 id="1-Implicit-versus-Explicit-Orchestration"><a href="#1-Implicit-versus-Explicit-Orchestration" class="headerlink" title="1. Implicit versus Explicit Orchestration"></a>1. Implicit versus Explicit Orchestration</h3><ul>
<li>cache<ul>
<li>可重用的模块化的buffer抽象</li>
<li>implict: 发起请求的程序并不指定数据何时重用和清空</li>
<li>启发式(Heuristic)替换策略, 与workload无关</li>
<li>但对于特定领域的加速器, tag匹配等带来的面积和功耗开销也难以忍受</li>
</ul>
</li>
<li>Scratched Pad<ul>
<li>指定存储的地址范围, 实现显示数据编排和精确控制</li>
<li>常用于GPU的shared mem</li>
<li>避免了cache的硬件开销</li>
<li>Across fill和overlaping fill繁琐且易出错, 难组成层级化的存储</li>
</ul>
</li>
</ul>
<h3 id="2-Coupled-versus-Decoupled-Orchestration"><a href="#2-Coupled-versus-Decoupled-Orchestration" class="headerlink" title="2.  Coupled versus Decoupled Orchestration"></a>2.  Coupled versus Decoupled Orchestration</h3><ul>
<li><p>Coupled</p>
<ul>
<li>存取请求的发起者也接收响应.</li>
<li>Pros: <ul>
<li>数据需求和使用之前的同步性高效且直观</li>
</ul>
</li>
<li>Cons: <ul>
<li>难以实现数据填充(fill)和访问(access)之间的overlap—请求/响应者要来在请求者和消费者之间回变换角色</li>
</ul>
</li>
<li>必须为整个往返负载延迟保留传入数据图块的“着陆区(landing zone)”，这会增加对RAM资源的压力</li>
</ul>
</li>
</ul>
<ul>
<li><p>Decoupled</p>
<ul>
<li><p>单独的硬件模块（例如DMA或地址生成器（AGEN））负责将数据推送到一个或多个功能单元的staging buffer中.</p>
</li>
<li><p>为了掩盖延时, ==这些buffer通常是ping-pong buffers[1,2].</p>
</li>
<li><p>Pros:</p>
<ul>
<li>请求者可以以自己的速度运行, 返回的数据可以广播到多个使用者.</li>
<li>访存是feed-forward的, 只需要与相邻层级的存储结构之间的lantancy相关的landing zong,  而不是在整个层次结构之间round-trip(比如cache如果miss还要去访问高一级存储, 如果decoupled那么buffer的大小只需要掩盖L1到L2的延时)</li>
</ul>
</li>
<li><p>Cons:</p>
<ul>
<li>传统的DAE数据编排依然是隐式的, 使用cache的管理机制</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/06/12/HYUbECoueQTwhqa.png" alt=""></p>
<h3 id="3-Synchronization-Concerns"><a href="#3-Synchronization-Concerns" class="headerlink" title="3. Synchronization Concerns"></a>3. Synchronization Concerns</h3><p>何时load一个new tile? 过早会导致数据被覆盖, 过晚会导致性能损失. </p>
<p>通过脉动阵列来约束tile的执行时间是一种办法. 对于涉及片外访问或者条件执行的系统, 这些时限过于保守.</p>
<p>本文采用ready-valid握手协议, 也可以使用其他micro-protocols(例如TRY/ACK). 本文提供了一个EDDO storage idiom，它在staging buffer操作本身中封装了细粒度的同步。</p>
<h2 id="The-Buffet-Storage-Idiom"><a href="#The-Buffet-Storage-Idiom" class="headerlink" title="The Buffet Storage Idiom"></a>The Buffet Storage Idiom</h2><p><img src="https://i.loli.net/2020/06/12/omPiChJxk5trX1S.png" style="zoom: 67%;" /></p>
<p>上图给出了buffet的数据编排模型, 它属于表1中的EDDO象限. 相较于DMA, 采用decoupled AGEN扩大了解耦的范围.</p>
<p>在buffet中，有限状态机控制四个基本存储操作：</p>
<ol>
<li>Fill(data)</li>
<li>Read(index)</li>
<li>Update(index, data): </li>
<li>Shrink(num)</li>
</ol>
<p>上级存储如DRAM通过<strong>FILL</strong>操作填入数据. 下级模块（例如DataPath）则通过<strong>Read</strong>和<strong>Update</strong>操作来处理buffet中的数据. <strong>Shrink</strong>操作从窗口中删除数据.</p>
<p><img src="https://i.loli.net/2020/06/12/kprVbnS1IgGwmxu.png" style="zoom:67%;" /></p>
<h3 id="1-Buffet-Operational-Behavior"><a href="#1-Buffet-Operational-Behavior" class="headerlink" title="1. Buffet Operational Behavior"></a>1. Buffet Operational Behavior</h3><p><img src="https://i.loli.net/2020/06/12/PcMjgDhnptIOEfV.png" alt="image-20200611205302228" style="zoom: 50%;" /></p>
<p>❶新传输的数据通过Fill逻辑装入RAM, 这一步类似于传统的FIFO, 数据不带有地址信息. Local地址的生成依赖于填充顺序.</p>
<p>❷与FIFO不同的是Read请求包含一个额外的Index, 允许以与接收数据不同的顺序读取数据. 这一index是相对于staging buffer中的oldest installed datum. 这一缩影不能超出RAM的大小.  传统的FIFO只要为非空，就会声明Pop.Vld. 在buffet中，请求数据的存在是索引的函数.  只有被请求的数据已被填充, 才会设置ReadRsp.VLD.</p>
<p>❸除了索引读取之外，与FIFO的一个显着区别是活动窗口内的数据元素可以就地修改，我们将其称为Update路径.</p>
<p>❹ shrink路径描述了从buffet中删除暂存数据的逻辑。此操作采用size参数，并从活动窗口中删除那么多元素。此操作仅更新内部记分板-不会发生数据移动。credits被释放到Fill AGEN，表明有空间可以进行另一次批量传输. 主张谁使用数据(生成index)谁shrink.</p>
<p><img src="https://i.loli.net/2020/06/12/uZ1agqPvn9zxKRo.png" alt="image-20200611211210544" style="zoom:80%;" /></p>
<h3 id="2-Buffet-Synchronization-Details"><a href="#2-Buffet-Synchronization-Details" class="headerlink" title="2. Buffet Synchronization Details"></a>2. Buffet Synchronization Details</h3><ul>
<li>需要显式硬件同步的情况由算法1中的“wait_until”调用表示。</li>
<li>由于公式1中的操作顺序，许多其他同步情况都可以在不需要显式硬件支持的情况下处理，如图4所示。</li>
<li>RAW冒险检查—计分板<ul>
<li>will_update 用于表示datapath即将修改当前阶段的值</li>
<li>如果后续的<strong>Read</strong>请求正在被修改的索引，则响应将stall—这与读取尚未填充的索引没有区别</li>
<li><strong>FILL</strong>写入时不需要检查</li>
<li>定制化—如果确定没有RAW冒险, 可以删除RAW检查, 如果<strong>FILL</strong>与<strong>UPDATE</strong>互斥, 可以共享一个写端口. </li>
</ul>
</li>
<li><strong>SHRINK</strong>与<strong>FILL</strong>之间的同步<ul>
<li>算法1中对<strong>SHRINK</strong>保守的使用显示同步—wait_until(num&lt;occupancy).</li>
<li>图4将其描述为隐式同步, 详见第四节</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/06/12/On4vEXflL9IuGKk.png" alt="image-20200611212533286" style="zoom:67%;" /></p>
<h3 id="3"><a href="#3" class="headerlink" title="3."></a>3.</h3><h3 id="4-Composition-of-Buffets"><a href="#4-Composition-of-Buffets" class="headerlink" title="4. Composition of Buffets"></a>4. Composition of Buffets</h3><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h3 id="1-文章的主要内容"><a href="#1-文章的主要内容" class="headerlink" title="1. 文章的主要内容"></a>1. 文章的主要内容</h3><h3 id="2-存在哪些缺陷"><a href="#2-存在哪些缺陷" class="headerlink" title="2. 存在哪些缺陷"></a>2. 存在哪些缺陷</h3><h3 id="3-有什么构思"><a href="#3-有什么构思" class="headerlink" title="3. 有什么构思"></a>3. 有什么构思</h3><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote>
<p>[1] J. Cong, M. A. Ghodrat, M. Gill, B. Grigorian, K. Gururaj, and G. Reinman. Accelerator-rich architectures: Opportunities and progresses. In Proceedings of the Design Automation Conference (DAC), 2014.<br>[2] E. G. Cota, P. Mantovani, G. D. Guglielmo, and L. P. Carloni. An analysis of accelerator coupling in heterogeneous architectures. In 2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC), pages 1–6, June 2015.</p>
</blockquote>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>计算机体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title>算法及算法的复杂度</title>
    <url>/2020/06/24/3_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95%E5%8F%8A%E5%A4%8D%E6%9D%82%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="算法及算法效率的度量方法"><a href="#算法及算法效率的度量方法" class="headerlink" title="算法及算法效率的度量方法"></a>算法及算法效率的度量方法</h1><h2 id="1-算法"><a href="#1-算法" class="headerlink" title="1. 算法"></a>1. 算法</h2><h3 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义:"></a>1.1 定义:</h3><p>算法是解决特定问题求解步骤的描述, 在计算机中为指令的有限序列, 并且每条指令表示一个或多个操作.</p>
<h3 id="1-2-算法的特性"><a href="#1-2-算法的特性" class="headerlink" title="1.2 算法的特性"></a>1.2 算法的特性</h3><ul>
<li>输入和输出</li>
<li>有穷性: 有合理边界</li>
<li>可行性: 每一步都可以通过有限步骤实现</li>
<li>确定性: 每一步都有确定含义, 不存在二义性</li>
</ul>
<h3 id="1-3-算法设计的要求"><a href="#1-3-算法设计的要求" class="headerlink" title="1.3 算法设计的要求"></a>1.3 算法设计的要求</h3><ul>
<li>正确性: 输入,输出和加工处理无歧义性, 能正确反映问题的需求, 能得到问题的正确答案</li>
<li>可读性: 便于阅读理解和交流</li>
<li>健壮性: 当输入数据不合法时也能得到相关处理</li>
<li>时间效率低空间效率高</li>
</ul>
<p>经过分析发现, 一个用高级语言编写的程序在计算机上运行所消耗的时间取决于下列因素:</p>
<ol>
<li>算法的策略方法</li>
<li>编译产生的代码质量</li>
<li>问题的输入规模</li>
<li>机器执行指令的速度</li>
</ol>
<p>第一条是算法好坏的根本, 一个程序的运行时间, 依赖于<strong>算法的好坏</strong>和<strong>问题的输入规模</strong>.</p>
<h2 id="2-算法的时间复杂度"><a href="#2-算法的时间复杂度" class="headerlink" title="2. 算法的时间复杂度"></a>2. 算法的时间复杂度</h2><h3 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h3><p>在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作：T(n) = O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。</p>
<p>通过大写O[ ]的方法体现时间复杂度的计法, 称为大O记法.</p>
<h3 id="2-2-推导大O阶方法"><a href="#2-2-推导大O阶方法" class="headerlink" title="2.2 推导大O阶方法"></a>2.2 推导大O阶方法</h3><p>O(1)叫做常数阶；O(n)叫做线性阶；O(n^2)叫做平方阶。 </p>
<ol>
<li><p>用常数1取代运行时间中的所有加法常数, 没有加法的常数不予考虑。</p>
</li>
<li><p>在修改后的运行次数函数中，只保留最高阶项。</p>
</li>
<li><p>如果最高阶项存在且不是1，则去除与这个项相乘的常数。</p>
</li>
</ol>
<p>得到的结果就是大O阶。 </p>
<p>如果你没看懂，那继续往下看，笔者以例子与你详细介绍：</p>
<p><strong>例子1：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> sum=<span class="number">0</span>,i = <span class="number">0</span>;i &lt; N;i++)  <span class="comment">//1、</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt;N;j++)     <span class="comment">//2、</span></span><br><span class="line">        sum=sum+i*j;            <span class="comment">//3、</span></span><br></pre></td></tr></table></figure>
<p>我们以一个语句记为1次来分析：</p>
<p>1、1+ (N+1)+N （这里定义两个变量共一次，而中间循环 理论是判断是N次,但是实际上应该是N+1 最后等于N时还有判断1次 0~N 故为N+1，循环变量的递增一共是N次）</p>
<p>2、N+N(N+1)+NN（这里由第一个循环进入第二个循环，一共是N次，那么将会定义N次，单独分析判断语句它将会像第一层循环一样，一个判断N次 再算上 第一次循环进入第二次循环共有N次 故 为N(N+1) 后面类似 NN ）</p>
<p>3、NN（第二层循环进入最里面语句 N次 第一层循环进入第二层循环 共N次 故实际为NN次）</p>
<p>那么累加一下:<br>1+(N+1)+N+N(N+1)+NN+NN 保留最高项 N * N, 故算法的时间复杂度为O(N^2)</p>
<p><strong>例子2:</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> sum = <span class="number">0</span>,i = <span class="number">1</span>;i &lt; N;i = i*<span class="number">2</span>)   <span class="comment">//1、</span></span><br><span class="line">        sum = sum+i*j;                 <span class="comment">//2、</span></span><br></pre></td></tr></table></figure>
<p>看到这程序片段，你是不是一眼就得出答案了？如果你不注意的话，你的答案肯定是O(N)，对了吗？<br>先告诉你答案为O(log(N))，你可以试试代个确切的N值进去 看一下次数,自己体会一下，那么下面我和大家一起分析下：</p>
<p>1、1+log(N)+1+log(N)</p>
<p>2、log(N)</p>
<p>其实这里做判断的时候，应该看一下循环变量的递增方式，这里它是i = i * 2 也就是 $2^x=N$ 那么$X=\log_2(N)$, X是次数，在计算复杂度里面，一般省略底数，也就是直接写log(N), 其他的计算方法与上面的解释一致。</p>
<p><strong>例子3:</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> sum=<span class="number">0</span>,i = <span class="number">0</span>;i&lt;N;i++)          <span class="comment">//1、</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j &lt; N;j = j*<span class="number">2</span>)      <span class="comment">//2、</span></span><br><span class="line">        sum=sum+i*j;                  <span class="comment">//3、</span></span><br></pre></td></tr></table></figure>
<p>分析:<br>1、1+N+1+N</p>
<p>2、N+N(log(N)+1)+Nlog(N)</p>
<p>3、Nlog(N)</p>
<p>将它们累加并保留高阶项并去除常数, 得到时间复杂度O(Nlog(N))</p>
<p><strong>例子4</strong>:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> sum = <span class="number">0</span>,i = <span class="number">0</span>; i &lt; n; i++)    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = i; j &lt; n; j++)        </span><br><span class="line">       sum += i*j</span><br></pre></td></tr></table></figure>
<p>分析:</p>
<p>总的执行次数为n+(n-1)+(n-2)+…+1=(N^2)/2+n/2</p>
<p>只保留高阶项并去除与这个项相乘的常数, 最终这段代码的复杂度为O(n^2)</p>
<h3 id="2-3-常见的时间复杂度"><a href="#2-3-常见的时间复杂度" class="headerlink" title="2.3 常见的时间复杂度"></a>2.3 常见的时间复杂度</h3><div class="table-container">
<table>
<thead>
<tr>
<th>执行次数函数</th>
<th>阶</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>$42$(常数)</td>
<td>O(1)</td>
<td>常数阶</td>
</tr>
<tr>
<td>$2n+3$</td>
<td>O(n)</td>
<td>线性阶</td>
</tr>
<tr>
<td>$3n^2+2n+1$</td>
<td>O(n^2)</td>
<td>平方阶</td>
</tr>
<tr>
<td>$5\log_2n+19$</td>
<td>O(log(n))</td>
<td>对数阶</td>
</tr>
<tr>
<td>$2n+3n\log_2n+19$</td>
<td>O(nlog(n))</td>
<td>nlog(n)阶</td>
</tr>
<tr>
<td>$6n^3 + 2n^2 + 3n +4$</td>
<td>O(n^3)</td>
<td>立方阶</td>
</tr>
<tr>
<td>$2^n$</td>
<td>O(2^n)</td>
<td>指数阶</td>
</tr>
</tbody>
</table>
</div>
<p>常用时间复杂度耗费时间排序:</p>
<script type="math/tex; mode=display">
O(1)\lt O(\log n) \lt O(n) \lt O(n\log n) \lt  O(n^2) \lt O(n^3) \lt O(2^n) \lt O(n!)\lt O(n^n)</script><p>一般而言, 指数阶$O(2^n)$和阶乘阶$O(n!)$会使运行时间大到不可估计, 一般不考虑这种不切实际的算法时间复杂度.</p>
<h3 id="2-4-最坏情况与平均情况"><a href="#2-4-最坏情况与平均情况" class="headerlink" title="2.4  最坏情况与平均情况"></a>2.4  最坏情况与平均情况</h3><p>比如查找数组中的某个数字, 最好情况是第一次找到, 复杂度为O(1), 最差是最后一次找到, 那么复杂度为O(n)</p>
<ul>
<li><p><strong>最坏情况</strong>是一种保障, 保证运行时间不会再坏了, <strong>除非特殊指定, 我们提到的运行时间都是最坏情况的运行时间</strong></p>
</li>
<li><p><strong>平均时间</strong>是所有情况中最有意义的, 因为它是期望运行的时间, 一般很难估算得到, 往往是通过一定量的数据实验得到</p>
</li>
</ul>
<h2 id="3-算法的空间复杂度"><a href="#3-算法的空间复杂度" class="headerlink" title="3. 算法的空间复杂度"></a>3. 算法的空间复杂度</h2><h3 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1 定义"></a>3.1 定义</h3><p>算法的空间复杂度通过计算算法所需的存储空间实现, 算法空间复杂度计算公式记作: S(n) = O(f(n)), 其中n为问题的规模, f(n)为语句所占空间的函数.</p>
<p>一般情况下, 一个程序在机器上执行时,除了需要存储程序本身的指令、常数、变量和输入数据外,还需要存储对数据操作的存储单元,若输入数据所占空间只取决于问题本身,和算法无关,这样只需要分析该算法在实现时所需的辅助单元即可。若算法执行时所需的辅助空间相对于输入数据量而言是个常数, 则称此算法为原地工作, 空间复杂度为 O(1) 。</p>
<p>在写代码时完全可以通过空间换时间.  通常我们不用限定词使用”复杂度”时通常都指时间复杂度. </p>
<h3 id="3-2-计算方法"><a href="#3-2-计算方法" class="headerlink" title="3.2 计算方法"></a>3.2 计算方法</h3><p><strong>1. 空间复杂度 O(1)</strong><br>如果算法执行所需要的临时空间不随着某个变量n的大小而变化，即此算法空间复杂度为一个常量，可表示为 O(1)</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">2</span>;</span><br><span class="line">++i;</span><br><span class="line">j++;</span><br><span class="line"><span class="keyword">int</span> m = i + j;</span><br></pre></td></tr></table></figure>
<p>变量 i、j、m 所分配的空间都不随着处理数据量变化，因此它的空间复杂度 S(n) = O(1)</p>
<p><strong>2. 空间复杂度 O(n)</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] m = <span class="keyword">new</span> <span class="keyword">int</span>[n]</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>; i&lt;=n; ++i)</span><br><span class="line">&#123;</span><br><span class="line">   j = i;</span><br><span class="line">   j++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码中，第一行new了一个数组出来，这个数据占用的大小为n，这段代码的2-6行，虽然有循环，但没有再分配新的空间，因此，这段代码的空间复杂度主要看第一行即可，即 S(n) = O(n)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读笔记--卷积神经网络加速器最优设计空间</title>
    <url>/2020/06/15/5_%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-Optimizing-the-Convolution-Operation-to-Accelerate/</url>
    <content><![CDATA[<h1 id="Optimizing-the-Convolution-Operation-to-Accelerate-Deep-Neural-Networks-on-FPGA"><a href="#Optimizing-the-Convolution-Operation-to-Accelerate-Deep-Neural-Networks-on-FPGA" class="headerlink" title="Optimizing the Convolution Operation to Accelerate Deep Neural Networks on FPGA"></a>Optimizing the Convolution Operation to Accelerate Deep Neural Networks on FPGA</h1><blockquote>
<p>原文: Ma, Y., et al. (2018). “Optimizing the Convolution Operation to Accelerate Deep Neural Networks on FPGA.” IEEE Transactions on Very Large Scale Integration (VLSI) Systems 26(7): 1354-1367.</p>
</blockquote>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="1-作者想要解决什么问题"><a href="#1-作者想要解决什么问题" class="headerlink" title="1. 作者想要解决什么问题"></a>1. 作者想要解决什么问题</h3><p>卷积加速方案会显著影响CNN加速器的效率和性能。卷积涉及具有四个循环级别的乘法和累加运算，这带来了较大的设计空间。但先前的工作要么采用有限的循环优化技术，例如循环展开(unrollilng)，分块(tilling)和交换(interchange)，要么仅在加速器体系结构和数据流已经固定之后才调整一些设计变量。最终的加速器几乎无法利用数据重用并有效地管理数据移动。</p>
<h3 id="2-通过什么理论或者模型来解决"><a href="#2-通过什么理论或者模型来解决" class="headerlink" title="2. 通过什么理论或者模型来解决"></a>2. 通过什么理论或者模型来解决</h3><p>本文通过基于多个设计变量定量分析和优化CNN加速器的设计目标（例如内存访问）来克服上述障碍。<strong>然后，本文提出了硬件CNN加速的特定数据流，以最大程度地减少数据通信，同时最大化资源利用率以实现高性能。</strong></p>
<h3 id="3-给出了什么答案"><a href="#3-给出了什么答案" class="headerlink" title="3. 给出了什么答案"></a>3. 给出了什么答案</h3><p>通过实现包括NiN，VGG-16和ResNet-50 / ResNet152的端到端CNN进行推理，演示了提出的CNN加速方案和体系结构。对于VGG-16  CNN，在Intel Stratix V和Arria 10 FPGA上，总体吞吐量分别达到348 GOPS和715 GOPS.</p>
<h2 id="I-引言"><a href="#I-引言" class="headerlink" title="I. 引言"></a>I. 引言</h2><h3 id="1-研究背景"><a href="#1-研究背景" class="headerlink" title="1.研究背景"></a>1.研究背景</h3><p>现代FPGA允许定制架构，并可以利用数百到数千个片上DSP模块。但是，在将CNN映射到FPGA上仍然存在重大挑战。</p>
<p>深度CNN算法具有数十到数百个层，在大小和配置方面，各层之间存在显着差异。  FPGA上有限的计算资源和存储容量使CNN的最佳映射任务（例如，使受能耗限制的延时最小化，或者相反）成为一个复杂的多维优化问题。片外通信的高成本是实现更高性能和更低能耗的另一个主要障碍。实际上，与大量数据移动和存储器访问相关的能源成本通常超过了计算的能源消耗。由于这些原因，基于FPGA的高能效CNN硬件加速需要同时最大化资源利用和数据重用，以及最小化数据通信。</p>
<h3 id="2-研究现状"><a href="#2-研究现状" class="headerlink" title="2. 研究现状"></a>2. 研究现状</h3><p>在CNN中，卷积由沿着kernel和特征图滑动的<strong>四个level的循环执行</strong>，如图1所示。这产生了一个庞大的设计空间，其中包括用于：实现并行性，计算顺序和对大数据集进行划分的各种选择，将数据分成较小的块以适合片上存储器等。这些问题可以通过现有的循环优化技术]处理，例如循环展开，分块和交换。</p>
<p><img src="https://i.loli.net/2020/06/15/AhqwfLtMNJpegar.png" alt="image-20200615163047678"></p>
<p>尽管已经有加速器采用了这些技术，但是尚未对这些技术对设计效率和性能的影响进行系统和充分的研究。如果没有充分研究卷积的循环操作，就很难为高吞吐量的CNN实现有效地自定义数据流和体系结构。</p>
<h3 id="3-基于哪些假设"><a href="#3-基于哪些假设" class="headerlink" title="3. 基于哪些假设"></a>3. 基于哪些假设</h3><p>CNN中超过90％的运算都涉及卷积操作。因此，有理由认为，加速方案应侧重于并行计算的管理以及跨多个级别的存储器（例如，片外动态随机存取存储器（DRAM），片上存储器和  本地寄存器）的数据存储和访问的组织。</p>
<ol>
<li>我们对卷积运算的三种循环优化技术进行了深入分析，并使用相应的设计变量<strong>对加速方案进行了数值表征</strong>。</li>
<li>根据设计变量的配置，定量估算CNN加速器的设计目标（例如延迟，访存）。</li>
<li>提出了一种有效的卷积加速策略和数据流，旨在最<strong>小化数据通信和内存访问</strong>。</li>
<li>数据路由（data router）的设计目的是处理卷积滑动操作（例如stride和padding）的不同设置，尤其是对于高度不规则的CNN。</li>
<li>设计了一种相应的硬件体系结构，该体系结构充分利用了计算资源以实现高性能和高效率，并且对于所有层而言都是统一且可重复使用的。</li>
</ol>
<h2 id="II-卷积的加速—关键设计变量"><a href="#II-卷积的加速—关键设计变量" class="headerlink" title="II. 卷积的加速—关键设计变量"></a>II. 卷积的加速—关键设计变量</h2><h3 id="1-通用的CNN加速器系统"><a href="#1-通用的CNN加速器系统" class="headerlink" title="1. 通用的CNN加速器系统"></a>1. 通用的CNN加速器系统</h3><p>CNN算法设计大量数据和权重，片上存储不足以存储所有数据。因此，典型的CNN加速器包括三个层次的存储层次结构：1）外部存储器； 2）片上缓存；3）PE关联的寄存器</p>
<p><img src="https://i.loli.net/2020/06/15/UWRjYhspAbvazd1.png" alt="image-20200615164907018"></p>
<p>基本流程是将数据从外部存储器获取到片上缓冲器，然后将其馈送到寄存器和PE中。  PE计算完成后，结果将传输回片上缓冲区，并在必要时传输到外部存储器，这些数据将用作后续层的输入。</p>
<h3 id="2-卷积循环"><a href="#2-卷积循环" class="headerlink" title="2. 卷积循环"></a>2. 卷积循环</h3><p>卷积是由四个级别的循环实现的，如图1中的伪代码所示，如图3所示。为了有效地映射和执行卷积循环，可以使用三种循环优化技术，即循环展开(unrolling)，循环分块(tilling)和循环交换(interchange)用于定制具有三个级别的内存层次结构的加速器的计算和通信模式。</p>
<p><img src="https://i.loli.net/2020/06/15/6KTSDQXbq3ZasFg.png" alt="image-20200615165112556"></p>
<h3 id="3-循环优化和设计变量"><a href="#3-循环优化和设计变量" class="headerlink" title="3. 循环优化和设计变量"></a>3. 循环优化和设计变量</h3><p>图3使用多个维度（dimensions）描述给定CNN的每个卷积层的特征图和卷积核尺寸。循环展开和循环分块的硬件设计变量将确定加速因子和硬件占用空间。表I列出了本文中使用的所有dimensions和variables。</p>
<p><img src="https://i.loli.net/2020/06/15/6QXrBi1oC38wFRH.png" alt="image-20200615165538174"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">符号</th>
<th>意义</th>
<th>符号</th>
<th>意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">$N_{kx}$</td>
<td>卷积窗宽度</td>
<td>$N_{ky}$</td>
<td>卷积窗高度</td>
</tr>
<tr>
<td style="text-align:left">$N_{ix}$</td>
<td>Input Feature宽度</td>
<td>$N_{iy}$</td>
<td>Input Feature高度</td>
</tr>
<tr>
<td style="text-align:left">$N_{ox}$</td>
<td>Output Feature宽度</td>
<td>$N_{oy}$</td>
<td>Output Feature高度</td>
</tr>
<tr>
<td style="text-align:left">$N_{if}$</td>
<td>Input Features数量</td>
<td>$N_{of}$</td>
<td>Output Features数量</td>
</tr>
</tbody>
</table>
</div>
<p>循环展开设计变量$(P_{kx},P_{ky}),P_{if},(P_{ox},P_{oy}),P_{of}$，它们表示并行计算的次数。</p>
<p>循环分块设计变量$(T_{kx},T_{ky}),T_{if},(T_{ox},T_{oy}),T_{of}$，他们表示存四个循环中，存储在片上缓存的数据部分。</p>
<p>这些dimensions或者variables具有如下的约束条件。</p>
<script type="math/tex; mode=display">
1\le P* \le T* \le N*</script><p>输入和输出的变量的关系受(1)-(3)约束</p>
<p><img src="https://i.loli.net/2020/06/15/ijvfHAUz4ZYC29p.png" alt="image-20200615172103274" style="zoom: 67%;" /></p>
<h4 id="1-1-循环展开"><a href="#1-1-循环展开" class="headerlink" title="1.1 循环展开"></a>1.1 循环展开</h4><p>如图4-7所示，展开不同的卷积循环会导致不同的计算并行化，这会影响有关数据重用机会和内存访问模式的最佳PE体系结构。</p>
<ul>
<li>Loop-1:在一个cycle内同时计算同一特征图和统一卷积窗中不同位置($P_{kx} \times P_{ky}$数量)的像素,  <strong>相当于并行一个卷积窗的不同元素</strong>. </li>
<li>Loop-2:同时计算$P_{if}$数量的，来自不同特征图/kernel,  同一位置的乘法.  <strong>相当于多个特征图同时做卷积</strong>.</li>
<li>Loop-3:在每个周期中，将来自相同特征图中不同（x，y）位置的($P_{ix}\times P_{iy}$数量)像素数乘以相同的权重,   因此，该重量可以重复使用$P_{ix}\times P_{iy}$次. <strong>相当于同一卷积窗卷积同一图像不同位置</strong>.</li>
<li>Loop-4:在每个周期中，输入特征图的一个像素乘以相同（x，y）位置处, 但来自不同的Kernel的$P_{of}$数量的权重，并且该像素被重用$P_{of}$次。<strong>相当于多个卷积窗卷积同一个特征图.</strong></li>
</ul>
<p><img src="https://i.loli.net/2020/06/15/B5OKNTdglhCrGaE.png" alt="image-20200615172358099" style="zoom:80%;" /></p>
<p><img src="https://i.loli.net/2020/06/15/op2jV9MCFedQnDx.png" style="zoom:80%;" /></p>
<p>四个卷积循环的展开变量值共同确定并行MAC操作的总数以及所需乘法器数量（Pm）</p>
<p><img src="https://i.loli.net/2020/06/15/2WjGodfwNt4yVbX.png" alt="image-20200615174850563" style="zoom: 67%;" /></p>
<h4 id="1-2-循环分块"><a href="#1-2-循环分块" class="headerlink" title="1.2 循环分块"></a>1.2 循环分块</h4><p>循环展开用于将整个数据划分为多个块，这些块可以容纳在片上缓存中，如图8所示。通过正确分配循环切片大小，可以增加数据的位置以减少DRAM访问的次数。</p>
<p><img src="https://i.loli.net/2020/06/15/5eJkWvogZlXnhtm.png" alt="image-20200615175142153" style="zoom:80%;" /></p>
<p>循环分块决定了片上缓存的下界：</p>
<ul>
<li><p>输入像素buffer的大小至少为：$Tix \times Tiy \times Tif \times (pixel_datawidth)$</p>
</li>
<li><p>权重buffer的大小至少为：$Tkx \times Tky \times Tif \times Tof \times (pixel_datawidth)$</p>
</li>
<li><p>输出buffer的大小至少为：$Tox \times Toy \times Tof \times (pixel_datawidth)$</p>
</li>
</ul>
<h4 id="1-3-循环交换"><a href="#1-3-循环交换" class="headerlink" title="1.3 循环交换"></a>1.3 循环交换</h4><p>循环交换确定四个卷积循环的顺序计算顺序。循环交换有两种，即Intratile（tile内）和Intertile（tile间）循环顺序。</p>
<ul>
<li>Intratile循环顺序决定了从片上缓冲器到PE的数据移动方式。 </li>
<li>Intertile循环顺序确定了数据从外部存储器到片上缓冲器的移动。</li>
</ul>
<h2 id="III-硬件加速设计目标的定量分析"><a href="#III-硬件加速设计目标的定量分析" class="headerlink" title="III. 硬件加速设计目标的定量分析"></a>III. 硬件加速设计目标的定量分析</h2><h3 id="1-计算延时"><a href="#1-计算延时" class="headerlink" title="1. 计算延时"></a>1. 计算延时</h3><p>每层乘法操作数量（$Nm$）</p>
<p><img src="https://i.loli.net/2020/06/15/AZcJwFHNxnmMqEp.png" alt="image-20200615181004450" style="zoom:67%;" /></p>
<p>理想情况下，每层的计算周期数应为$Nm / Pm$，而$Pm$是乘法器数量。但是，对于不同的循环展开和分块大小，不一定必须对每个卷积维度都能充分利用乘法器。每层的实际计算周期数为</p>
<p><img src="https://i.loli.net/2020/06/15/pxYsW6rCMqA5UcQ.png" alt="image-20200615181129238" style="zoom:67%;" /></p>
<p>其中的$\lceil  \rceil$表示向上取整</p>
<p>在这里，我们假设乘法器连续接收输入数据而没有空闲周期。如果N∗与T∗的比率或T∗与P ∗的比率不是整数，则乘法器或外部存储器transaction未得到充分利用。除了考虑计算延迟之外，还必须考虑整个系统延迟的内存传输延迟。</p>
<h3 id="2-部分和存储"><a href="#2-部分和存储" class="headerlink" title="2. 部分和存储"></a>2. 部分和存储</h3><p>部分和(partial sum)有时需要在接下来的几个周期中存储在内存中，有时必须在PE之间移动。有效的加速策略必须使部分和的数量最少，并尽快在本地进行处理以减少数据移动。</p>
<p>计算存储在存储器中的部分和（#psum）的流程图如图9所示</p>
<p><img src="https://i.loli.net/2020/06/15/g4XasvzWZrC6IUV.png" alt="image-20200615212926967" style="zoom: 67%;" /></p>
<p>Loop1和loop2全展开时没有部分和，可直接写回DRAM.</p>
<p>P <em>或 T </em>确定的部分和的数量很小，可以存储在本地寄存器（9.2）中。 或片内缓冲器（9.3）。</p>
<p>如果loop tile不能包含Loop-1和Loop-2的所有数据，则需要将一个tile的部分和存储在片上或片外存储器中，直到被另一tile消耗为如（9.6）-（9.9）所示。</p>
<p>总结下来就是, 循环的计算顺序也会影响部分和的数量，并且循环1和Loop-2的计算越早，部分和的数量就越少。将部分和存储在不同级别的存储器层次结构中的要求极大地恶化了数据移动和相关的能源成本。</p>
<h3 id="3-数据复用"><a href="#3-数据复用" class="headerlink" title="3. 数据复用"></a>3. 数据复用</h3><p>重用的两种类型：</p>
<ul>
<li>空间重用（Spatial Reuse）：意味着从片上缓冲器读取数据后，单个像素或权重将在一个时钟周期内用于多个并行乘法器。</li>
<li>时间重用（Temporal Reuse）：时间重用意味着单个像素或权重用于多个连续周期。</li>
</ul>
<p>每个周期具有Pm个并行乘法运算需要将Pm像素和Pm权重馈入乘法器。每个周期所需的d权重数为</p>
<p><img src="https://i.loli.net/2020/06/16/QsHfUTI32PeKp7d.png" alt="image-20200616170603273" style="zoom:67%;" /></p>
<p>如果Loop-1没有展开$(P_{kx} = 1，P_{ky} = 1)$，则每个周期所需的不同像素数$(P_{px})$</p>
<p><img src="https://i.loli.net/2020/06/16/zyxeXpL95qKTAEo.png" alt="image-20200616170419509" style="zoom: 67%;" /></p>
<p>权重在一个周期内在空间上重复使用的次数为</p>
<p><img src="https://i.loli.net/2020/06/16/EwSs5YmVD69c8yv.png" alt="image-20200616170846977" style="zoom:67%;" /></p>
<p>通过展开Loop-3$（P_{ix}&gt; 1$或$P_{iy}&gt; 1）$实现权重的空间重用。像素的数量在一个周期内在空间上被重用（Reuse_px）为</p>
<p><img src="https://i.loli.net/2020/06/16/zFdaY4rBNXkiMcq.png" alt="image-20200616171113765" style="zoom:67%;" /></p>
<p>如果未展开Loop-1，则Reuse_px为</p>
<p><img src="https://i.loli.net/2020/06/16/LHRFOgGDIhPCzJu.png" alt="image-20200616171214050" style="zoom:67%;" /></p>
<p>否则, Reuse_px为</p>
<p><img src="https://i.loli.net/2020/06/16/xeiqHz3Zlb7OrpE.png" alt="image-20200616171327803" style="zoom:67%;" /></p>
<h3 id="4-片上访存"><a href="#4-片上访存" class="headerlink" title="4. 片上访存"></a>4. 片上访存</h3><p>利用数据重用，可以显着减少片上缓冲区访问的次数。由于没有任何数据重用，因此片上缓冲器对像素和权重的总读取操作为<em>Nm</em>，因为每次乘法都需要一个像素和一个权重。通过数据重用，片上缓冲器读取权重的总数变为</p>
<p><img src="https://i.loli.net/2020/06/17/EnKmW8xDTjHqIOt.png" alt="image-20200616172246692" style="zoom:67%;" /></p>
<p>像素的读取操作总数为</p>
<p><img src="https://i.loli.net/2020/06/16/eHR1GlgS7JqE4kT.png" alt="image-20200616172419573" style="zoom:67%;" /></p>
<p>如果无法在一个图块内获得最终输出像素，则将其部分和存储在缓冲区中。每个周期的部分总和向缓冲区的读写操作数为$2×P_{of}×P_{ox}×P_{oy}$，所有部分和都由Loop-1 ($P_{kx},P_{ky}$)产生,  Loop-2（$P_{if}$）生成的乘积在乘法后立即求和。</p>
<p><img src="https://i.loli.net/2020/06/16/uQJcEHYK9TMVkx7.png" alt="image-20200616172827907" style="zoom:67%;" /></p>
<p>将输出像素写入片上缓冲区的次数（即<em>#write_px</em>）与给定CNN模型中输出像素的总数相同。最后，片上缓冲区访问的总数为</p>
<p><img src="https://i.loli.net/2020/06/16/IHOnqbFhseLKwyU.png" alt="image-20200616172906223" style="zoom:67%;" /></p>
<h3 id="5-片外访存"><a href="#5-片外访存" class="headerlink" title="5. 片外访存"></a>5. 片外访存</h3><p>DRAM访问的成本具有更高的延迟和能量,  通过具有足够大的片上缓冲区和适当的循环计算顺序，可以实现最少的DRAM访问次数，从而每个像素和权重仅需从DRAM传输一次。</p>
<p>估计DRAM访问次数的流程图如图10所示，其中<em>#DRAM_px</em>和<em>#DRAM_w</em>t分别表示一个输入像素和一个权重的DRAM访问次数。</p>
<p><img src="https://i.loli.net/2020/06/16/vjgP13nClhDkITu.png" alt="image-20200616173343725" style="zoom:67%;" /></p>
<p>从DRAM中取出所有数据后，应将其全部耗尽，然后将其踢出缓冲区。</p>
<p>因此，如果图块大小或片上缓冲区可以完全覆盖一层的所有输入像素或所有权重，则可以在图10中以（10.8）实现最小DRAM访问。</p>
<p>通过首先计算Loop-3，如图10中的（10.1）和（10.5）中所示，重用了存储在缓冲区中的权重并减少了<em>#DRAM_wt​</em>。</p>
<p>类似地，通过首先计算Loop-4，可以像（10.3）和（10.6）一样重用像素来减少<em>#DRAM_px</em>。<strong>但是，首先计算Loop-3或Loop-4可能会延迟Loop-1或Loop-2的计算，这将导致大量的部分和。</strong></p>
<h2 id="IV-State-of-the-art-CNN加速器所使用的加速方法"><a href="#IV-State-of-the-art-CNN加速器所使用的加速方法" class="headerlink" title="IV. State-of-the-art CNN加速器所使用的加速方法"></a>IV. State-of-the-art CNN加速器所使用的加速方法</h2><p>当前设计的循环展开策略可以分为四种类型：</p>
<ol>
<li>[Type-(A)]展开loop-1，loop-2，loop-4</li>
<li>[Type-(B)]展开loop-2，loop-4</li>
<li>[Type-(C)]展开loop-1，loop-3</li>
<li>[Type-(D)]展开loop-3，loop-4</li>
</ol>
<p><strong>Type-A</strong></p>
<p>在Kernel, Input, Output中实现并行。但Kernel（$N_{kx}×N_{ky}$）通常很小（≤11×11），因此它不能提供足够的并行度，并且其他循环需要进一步展开。一个更具挑战性的问题是，在给定的CNN模型（例如AlexNet和ResNet  ）中，不同卷积层的内核大小可能会有很大差异，这可能导致工作负载不平衡和PE的利用率低下。为了解决这个问题，需要为具有不同内核大小的层配置不同的PE，这会增加控制的复杂性。</p>
<p><strong>Type-B</strong></p>
<p>在Type-A和Type-B中，不会展开Loop-3，这意味着无法重用权重。Type-B仅展开Loop-2和Loop-4，但是第一卷积层的$Nif×Nof$通常很小（≤3×96）4，并且不能提供足够的并行度，这导致利用率和吞吐量较低。如果第一层受到计算限制，或者DRAM延迟不与计算重叠，那么吞吐量下降将影响整体性能，尤其是对于浅层CNN（例如AlexNet和NiN）而言。</p>
<p><strong>Type-C</strong></p>
<p>在Type-C中，Kernel窗口中的每一行都将完全展开（$P_{kx} =  N_{kx}$），并且Loop-3也将部分展开。通过这种方式，可以通过（15）中的由Loop-1和Loop-3引起的重叠来重用像素，并且还可以通过在（12）中展开Loop-3来实现权重重用。但是，Loop-4不会展开，并且无法实现进一步的像素重用。由展开Loop-1引起的PE效率问题也影响Type-C。</p>
<p><strong>Type-D</strong></p>
<p>在Type-D中，将Loop-3和Loop-4都展开，以便可以重用像素和权重。另外，在AlexNet，VGG和ResNet的所有卷积层中，$Nox×Noy×Nof$（≥7×7×64）非常大，因此即使对于具有约3600个DSP Slice的最大FPGA，也可以实现并行级别。<strong>通过这种方式，PE的统一配置和结构可以应用于所有卷积层。</strong></p>
<h2 id="V-具有特定设计变量的优化加速方案"><a href="#V-具有特定设计变量的优化加速方案" class="headerlink" title="V. 具有特定设计变量的优化加速方案"></a>V. 具有特定设计变量的优化加速方案</h2><h3 id="1-最小化延时"><a href="#1-最小化延时" class="headerlink" title="1. 最小化延时"></a>1. 最小化延时</h3><p>见公式(5)-(8)</p>
<p>为了充分利用PE，我们将变量P <em>设为所有卷积层的T </em>的公因子，并将T <em>设为N </em>的公因子，以充分利用外部存储。对于仅具有较小公因数的CNN模型，建议将$\lceil N ∗\rceil / T ∗ − N ∗ / T ∗$和$\lceil T ∗\rceil / P ∗ − T ∗ / P ∗$ (即余数)设置得尽可能小，以最大程度地减小因CNN模型的大小。</p>
<h3 id="2-最小化部分和存储"><a href="#2-最小化部分和存储" class="headerlink" title="2. 最小化部分和存储"></a>2. 最小化部分和存储</h3><p>为了减少部分和的数量和移动，Loop-1和Loop-2都应尽早计算或尽可能展开。为了避免展开第IV节中讨论的Loop-1的缺点并最大化第III-3节中讨论的数据重用，我们决定展开Loop-3（$Pox&gt;1$或$Poy&gt;1$）和Loop-4（$Pof&gt;1$）。这也意味着, 我们无法获得最小的部分和存储，如图9内的（9.1）。受<script type="math/tex">1≤P *≤T *≤N  *</script>的约束，部分和存储的第二个最小数由（9.2）实现图9中的（9.2）-（9.9）。为满足（9.2）的条件，我们首先对Loop-1和Loop-2进行串行计算，并确保对Loop-1和Loop-2的所需数据进行了缓存，即，$ Tkx = Nkx，Tky = Nky，Tif = Nif $。因此，我们只需要存储$ Pof×Pox×Poy $的部分和，可以将其保留在本地寄存器中，并且数据移动最少。</p>
<h3 id="3-最小化片上存储"><a href="#3-最小化片上存储" class="headerlink" title="3. 最小化片上存储"></a>3. 最小化片上存储</h3><p>通过展开Loop-3以重用权重（如公式（12）中所示）和展开Loop-4以便重用像素，如公式(14）中所示，可以最大程度地减少片上Buffer的访问次数。由于我们的部分和被保存在本地寄存器中，因此它们不会增加缓冲区访问和存储的开销。</p>
<h3 id="4-最小化片外访存"><a href="#4-最小化片外访存" class="headerlink" title="4. 最小化片外访存"></a>4. 最小化片外访存</h3><p>当我们首先计算Loop-1和Loop-2以减少部分和时，我们无法实现图10中（10.1）和（10.3）中所述的最小DRAM访问次数，其中一个卷积层的像素和权重均被未完全缓存。因此，我们只能通过为图10的（10.8）中的每一层的所有像素或所有权重分配足够的缓冲区大小来获得最小的DRAM访问。</p>
<p>然后，在最小化片上缓冲区大小的同时进行最小化DRAM访问的优化公式为</p>
<p><img src="https://i.loli.net/2020/06/16/zdPgrHhYyb6BjG3.png" alt="image-20200616201408416" style="zoom:67%;" /></p>
<p>其中<em>#Tile_pxLand</em> <em>#Tile_wtL</em>分别表示输入像素的分块块数和层L的权重，而<em>#CONVs</em>是卷积层数。<em>bits_BUF_px_wt</em>是像素缓冲区大小（<em>bits_BUF_px</em>）和权重缓冲区大小（<em>bits_BUF_wt</em>）的总和，由下式给出：</p>
<p><img src="https://i.loli.net/2020/06/16/xXpqME3hIGtL2CZ.png" alt="image-20200616201529075" style="zoom:67%;" /></p>
<p>像素缓冲区和权重缓冲区都必须足够大，以覆盖所有卷积层的一个切片块中的数据。表示为</p>
<p><img src="https://i.loli.net/2020/06/16/8Tq5hcF9fVJbYDM.png" alt="image-20200616201606094" style="zoom:67%;" /></p>
<p>其中<em>words_pxL</em>和<em>words_wtL</em>分别表示L层中一个分块的像素数和权重。这些以循环分块变量表示，如下所示：</p>
<p><img src="https://i.loli.net/2020/06/16/4eanUkZxrflCjmJ.png" alt="image-20200616201841590" style="zoom:67%;" /></p>
<p>其中<em>words_pxL</em>由输入和输出像素组成（20）中的分块数也由T∗变量确定</p>
<p><img src="https://i.loli.net/2020/06/16/8Gx5CD1BW7a3ru9.png" alt="image-20200616202025981" style="zoom:67%;" /></p>
<p>通过求解（20），我们可以找到$T*$变量的最佳配置，从而使DRAM访问和片上缓冲区的大小最小。但是，由于我们已经像第V-2节中那样设置了$Tkx = Nkx，Tky = Nky，Tif =  Nif$，因此我们只能通过调整$To x，To y$和$Tof$来实现次优解决方案，从而需要更大的缓冲区大小。如果可用的片上存储器足够，我们将$Tox$设置为$Nox$，以便可以缓冲整行，从而受益于DMA transaction。</p>
<p>最后，我们必须通过搜索$To y$和$To f$来求解（20），因为它具有非线性目标函数和带有整数变量的约束。由于VGG-16中的$To y$和$To f$由2×#CONVs  = 26个变量组成，并且每个变量可以具有大约四个可选值，分别受$T ∗ / P ∗ =$整数和$N ∗ / T ∗ =$整数的约束，因此，$ To y$和$To  f$配置约为$4^{26} = 4.5×10^{15}$，这成为一个巨大的求解空间。在ResNet-50 /  ResNet152中，＃CONV分别增加为53和155，这使得解决方案空间甚至更大，分别为$4^{106} = 6.6×10^{63}$和$4^{310} =  4.4×10^{186}$。因此，不可能列举所有候选解。</p>
<p>在本文中，我们建议根据经验为给定的利用CNN特性的片上存储容量找到令人满意的解决方案。  <strong>CNN通常在开始的几层中具有较大的像素数据量和较小的权重大小。当我们进入更深的层时，像素大小随着提取的特征而变小，权重大小随着更多的通道而变大。</strong></p>
<p>图11中说明了这种趋势，其中的条形表示每个卷积层中的数据大小。<strong>要受益于不同层中的数据分发属性，我们只需要使像素缓冲区完全覆盖最后几层，而权重缓冲区则完全覆盖开始的几层。然后，像素和权重都较大的中间层成为缓冲区大小的约束，我们只需要注意这些边界层，就可以大大缩小解决方案空间。</strong>图11中的虚线是我们发现的最小缓冲区大小，同时保证了最少的DRAM访问，并且边界层由箭头指出。如果该缓冲区大小仍然无法装入FPGA片上存储器，则我们需要更改切片策略或减小缓冲区大小，但要付出更多DRAM访问的代价。</p>
<p><img src="https://i.loli.net/2020/06/16/8reIBy6J9Yb7WFP.png" alt="image-20200616203031356" style="zoom: 67%;" /></p>
<h3 id="5-优化循环设计变量"><a href="#5-优化循环设计变量" class="headerlink" title="5. 优化循环设计变量"></a>5. 优化循环设计变量</h3><p>根据上述优化过程，我们提出了一种用于高性能和低通信量的CNN加速器的卷积加速方案，如图12所示。</p>
<p><img src="https://i.loli.net/2020/06/16/rCmFHdE5Ub1o7uQ.png" alt="image-20200616203335677" style="zoom:80%;" /></p>
<h4 id="循环展开："><a href="#循环展开：" class="headerlink" title="循环展开："></a>循环展开：</h4><p>对于所有卷积层，没有展开Loop1和Loop-2，这意味着$Pkx = 1，Pky = 1$和$Pif  =1$。根据（7）和（8），$Pox，Poy$和$Pof$为分别设置为特征图（$Nox，Noy$）和输出通道（$Nof$）的公因子，以充分利用乘法器。表II中列出了不同FPGA上不同CNN的$Pox$，$Poy$和$Pof$的配置，这些配置在很大程度上受到可用计算资源的限制。通过将$P  *$在所有卷积层上设置为常数，可以实现PE的统一结构和映射，从而降低体系结构的复杂性。</p>
<h4 id="循环分块"><a href="#循环分块" class="headerlink" title="循环分块"></a>循环分块</h4><p>对于循环展开，如第V-2节所述，如图12所示，设置$Tkx = Nkx，Tky = Nky，Tif =  Nif$，以便将Loop-1和Loop-2中使用的数据全部缓冲，设置$To x = Nox$使得DMA传输获益。 $To y$和$To f$的详细信息在第V-4节中已经描述过。</p>
<h4 id="循环交换"><a href="#循环交换" class="headerlink" title="循环交换"></a>循环交换</h4><p>我们首先按第V-B节所述依序计算Loop-1，然后计算Loop-2。最后，我们计算Loop-3和Loop-4，这两个循环的确切计算顺序不会对成本产生明显影响,  而是根据我们的$P <em>$和$T  </em>$选择(这句话不知道理解的对不对)。</p>
<p><img src="https://i.loli.net/2020/06/16/xYdwBE1bjmOuWeJ.png" alt="image-20200616204445613"  /></p>
<h2 id="VI-本文提出的CNN加速器"><a href="#VI-本文提出的CNN加速器" class="headerlink" title="VI. 本文提出的CNN加速器"></a>VI. 本文提出的CNN加速器</h2><h3 id="1-Data-Bus-From-Buffer-to-PE-BUF2PE"><a href="#1-Data-Bus-From-Buffer-to-PE-BUF2PE" class="headerlink" title="1. Data Bus From Buffer to PE (BUF2PE)"></a>1. Data Bus From Buffer to PE (BUF2PE)</h3><p>我们在图13中提出了BUF2PE数据总线，以使用FIFO实现数据流，以临时存储要由相邻寄存器阵列重用的像素。此方法类似于[22]中的行缓冲区设计，其中FIFO用于将多个特征行中的像素对齐到kernel窗口，以便可以在kernel窗口内采用并行，即展开Loop-1，而本文展开循环3以在一个特征图中进行并行计算。通过这种方式，简化了寄存器阵列内和寄存器阵列之间的布线，并且数据路由器可以遵循相同的模式进行卷积，具有不同的步幅和零填充，从而提高了加速器的灵活性。</p>
<p><img src="https://i.loli.net/2020/06/17/iAv5g2pm8eOsSH1.png" alt="image-20200617102152077"></p>
<p>BUF2PE数据总线的详细设计如图13所示。来自输入缓冲区的像素被加载到相应的寄存器中，如蓝色虚线框到蓝色实线框所示。然后，像素在周期0~5期间发送到PE或MAC单元，还发送到FIFO，等待相邻寄存器阵列重用。如图13中的紫色像素所示，除最右边的寄存器阵列外，在周期3开始从FIFO读取输入像素。同时，新像素从缓冲区馈入最右边的寄存器阵列。在本文中，由west zero padding引起的偏移是通过移动缓冲区和寄存器阵列之间的连接来处理的，而[15]必须通过填充偏移来更改输入缓冲区的一个地址内的存储模式，这会增加数据传输的复杂性从DRAM到缓冲区。</p>
<p>图14中以stride=1 和stride=2在特征图行级别上显示了粗粒度数据流。图14（a）中的数据流与图13相同，展示了8个周期之后更多的操作。</p>
<p>图14（b）给出了stride= 2, padding= 3的数据流,  它与stride= 1遵循相同的模式, 根据不同的stride和padding设置来调整缓冲区存储模式。由于north zero padding of 3将三行零添加到缓冲区。在stride= 2的情况下，每两行像素在$Poy$个 buffer banks中连续分布。在从DRAM接收像素期间，这些调整由缓冲区写使能和地址信号处理。</p>
<p>由于padding和stride的设置不同, 每个数据流都需要各种BUF2PE数据总线，并且这组数据总线称为数据路由器。全局控制逻辑控制数据路由器内部不同BUF2PE总线之间的切换。</p>
<p><img src="https://i.loli.net/2020/06/17/mIVRtsjuiB2T9l1.png" alt="image-20200617103126427"></p>
<h3 id="2-PE体系结构"><a href="#2-PE体系结构" class="headerlink" title="2. PE体系结构"></a>2. PE体系结构</h3><p>根据建议的加速策略和数据流设计图15所示的卷积层的PE体系结构。它由$Pox×Poy×Pof $个PE组成，我们体系结构中的每个PE都是一个独立的MAC单元，由一个乘法器和一个累加器组成。由于Loop-1和Loop-2不会展开，因此不需要加法器树即可对乘法器输出求和。在每个MAC单元内消耗部分和，直到获得最终结果为止，</p>
<p><img src="https://i.loli.net/2020/06/17/8hZgSMr5oD9EcRj.png" alt="image-20200617104033820"></p>
<p>从输入像素缓冲区读取的像素由$Pof$个MAC单元共享，滑动时重叠的像素也被数据路由器重用。从权重缓冲区读取的权重由$Pox×Poy $ 个MAC单元共享。所提出的体系结构通过参数化的Verilog代码实现，并且通过修改设计变量（例如$Pox，Poy和Pof$），可以高度扩展到FPGA甚至ASIC中的不同CNN模型。</p>
<p>在Loop-1和Loop-2完成之后，部分总和需要加上如图1所示的偏置，以获得最终的输出像素。因此，每隔$Nkx×Nky×Nif$个周期，MAC单元会将部分和输出到加法器中，并加上偏置。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文通过对循环优化技术进行数值表征，对卷积循环加速策略进行了深入分析。加速器目标和设计变量之间的关系进行了定量研究。提出了相应的新数据流和体系结构，以最大程度地减少数据通信并提高吞吐量。</p>
<hr>
<blockquote>
<p>更多内容欢迎关注我</p>
<p>博客:<a href="https://shawer.work/" target="_blank" rel="noopener">https://shawer.work/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>神经网络加速器</tag>
        <tag>计算机体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title>我的第一篇博客</title>
    <url>/2019/12/29/6_%E9%9A%8F%E7%AC%94/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="c60b1ad9f22f09a9905fa786aac12ca23e35ac28ef82a4d384ba02338c7309b0">2daa0e43d16059575e0358eeb13204c9334f10fe9f5b4c4ca9e491347ae1aac787a653f3bfdff483154faa9c306499459a543d8e0e9fdb7cb6a5691a3868df52cad9689da85c8199db4aac1924b04b538bf91d99cddcb7f67e38171e7d09e6b5597213a8b0d8533be2784f8c387f9f0e68d0da8bb048934a16c72aa145f07ad7ad2b10054f7f6b1d80b0d972ac6485d319be33fd5c92fbe1131f89956e7073ea85085780b1c6a34ebadafa0d52784ba9f0261bdd30c89b38edda4c7efe264159e6e8a362df38552661363061bfa6a36abe0affed58798e5a6d70904733b2ad67d59ed42e7b388d29ddb4d8010b266ca05db60cbedc9060a428ca1bad408deceeab54380c354fdfb78225304e7d4c88b8e72446d8af33f4178fb27faf0449b805d486d93cb7785dd7dbb3392434262aab7a601b8088edb79def0f6fdb4926f9d04f2c1e1aead921142879cb84a484b8e4dfcd34931c5fcea43e424ded1d1812eba22ca16c330fd68f276497435047212117eeb1a62d4c93242d72e10d6724aaad4dcfb180bc95b3f5b99e65330158bd894ce97a9c4fb53d4f5c1ea52ef8ff5dbe2648adca06564933bdac07b21b3cad5c719d3e3240f6c8552d75e8f2915a921e6d0843ea372193f682b95dcd3bf10c782b69c7ce44d3b0090bc7d681e2fc7b223cf6d6d0250200d0783bc24ad9075ab73f86040d8f679046798f5cd3a1ca8209329d43d6f89d643546670e222bb26ffd8b10a56ce2af5dbc3e12ae65c3f3216d657241a0657c72df14798ba83b10ccddbb47eef59f497761a407577164474a0c2e03e28634c6f9912748f2d6dd6a69b188d8cc2e21686e42bab33415c5f368932f753d1fd62ace6bbf3c7b75a9e2a799ed4d386784a9ce1405719dc52e00dc1f0c85e5c6ac756e1e14c66a268140ebf1b1ecfa515901fd273c9351202425498ae9b937346baa409fcfe66635c516435b9a929ec339333d2d8e0091b8bc155b1f24d6fe55d4d17d8a760648d92ccd7983b79df3cd5e2aa01f015c75216019495aabe0fedd9b61d1b5672d5643de5e7b7adff4dd66c76df3f67193d7e3812aca14eb90b0badc2dc2461c8a98524cb119b47ca1302e93962a861f229c0fdcc505cfb12451ec1bad993b4e8e23dee748821febba58e44b376a927b5b7a3d19439c3b9878319c543f34f7dec63c58fcf910fe08bb7335c34f277eedb08d61ac013b1c887783e609bfe2f17fe64abd6d402da318e9668de1a6d5b6ce48ceb45da8337e001be83a04e4351b653c4bbd9ee42d16b3c8639da1f7e5636130c198a212e168bc4dc35121d604ba0de0cb781467df42</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>转载:关于CPU Cache——程序员需要知道的事</title>
    <url>/2020/07/11/%E5%85%B3%E4%BA%8ECPU-Cache-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    <content><![CDATA[<blockquote>
<p>本文将介绍一些作为程序猿或者IT从业者应该知道的CPU Cache相关的知识</p>
<p>文章欢迎转载，但转载时请保留本段文字，并置于文章的顶部 作者：卢钧轶(cenalulu) 本文原文地址：<a href="http://cenalulu.github.io/linux/all-about-cpu-cache/" target="_blank" rel="noopener">http://cenalulu.github.io/linux/all-about-cpu-cache/</a></p>
</blockquote>
<p>先来看一张本文所有概念的一个思维导图</p>
<p><img src="http://cenalulu.github.io/images/linux/cache_line/mind_map.png" alt="mind_map"></p>
<a id="more"></a>
<h2 id="为什么要有CPU-Cache"><a href="#为什么要有CPU-Cache" class="headerlink" title="为什么要有CPU Cache"></a>为什么要有CPU Cache</h2><p>随着工艺的提升最近几十年CPU的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存主要是DRAM并且在访问速度上没有质的突破。因此，CPU的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的CPU通过FSB直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低CPU整体吞吐量。同时又由于内存数据访问的热点集中性，在CPU和内存之间用较为快速而成本较高的SDRAM做一层缓存，就显得性价比极高了。</p>
<h2 id="为什么要有多级CPU-Cache"><a href="#为什么要有多级CPU-Cache" class="headerlink" title="为什么要有多级CPU Cache"></a>为什么要有多级CPU Cache</h2><p>随着科技发展，热点数据的体积越来越大，单纯的增加一级缓存大小的性价比已经很低了。因此，就慢慢出现了在一级缓存(L1 Cache)和内存之间又增加一层访问速度和成本都介于两者之间的二级缓存(L2 Cache)。下面是一段从<a href="http://cenalulu.github.io/linux/all-about-cpu-cache/(www.akkadia.org/drepper/cpumemory.pdf" target="_blank" rel="noopener">What Every Programmer Should Know About Memory</a>)中摘录的解释：</p>
<blockquote>
<p>Soon after the introduction of the cache the system got more complicated. The speed difference between the cache and the main memory increased again, to a point that another level of cache was added, bigger and slower than the first-level cache. Only increasing the size of the first-level cache was not an option for economical rea- sons.</p>
</blockquote>
<p>此外，又由于程序指令和程序数据的行为和热点分布差异很大，因此L1 Cache也被划分成L1i (i for instruction)和L1d (d for data)两种专门用途的缓存。 下面<a href="https://datatake.files.wordpress.com/2015/01/cpu-cache-access-in-cpu-cycles.png" target="_blank" rel="noopener">一张图</a>可以看出各级缓存之间的响应时间差距，以及内存到底有多慢！</p>
<p><img src="http://cenalulu.github.io/images/linux/cache_line/latency.png" alt="latency"></p>
<h2 id="什么是Cache-Line"><a href="#什么是Cache-Line" class="headerlink" title="什么是Cache Line"></a>什么是Cache Line</h2><p>Cache Line可以简单的理解为CPU Cache中的最小缓存单位。目前主流的CPU Cache的Cache Line大小都是64Bytes。假设我们有一个512字节的一级缓存，那么按照64B的缓存单位大小来算，这个一级缓存所能存放的缓存个数就是<code>512/64 = 8</code>个。具体参见下图：</p>
<p><img src="http://cenalulu.github.io/images/linux/cache_line/cache_line.png" alt="img"></p>
<p>为了更好的了解Cache Line，我们还可以在自己的电脑上做下面这个有趣的实验。</p>
<p>下面这段C代码，会从命令行接收一个参数作为数组的大小创建一个数量为N的int数组。并依次循环的从这个数组中进行数组内容访问，循环10亿次。最终输出数组总大小和对应总执行时间。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;stdio.h&quot;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;sys&#x2F;time.h&gt;</span><br><span class="line"></span><br><span class="line">long timediff(clock_t t1, clock_t t2) &#123;</span><br><span class="line">    long elapsed;</span><br><span class="line">    elapsed &#x3D; ((double)t2 - t1) &#x2F; CLOCKS_PER_SEC * 1000;</span><br><span class="line">    return elapsed;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">#*******</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    int array_size&#x3D;atoi(argv[1]);</span><br><span class="line">    int repeat_times &#x3D; 1000000000;</span><br><span class="line">    long array[array_size];</span><br><span class="line">    for(int i&#x3D;0; i&lt;array_size; i++)&#123;</span><br><span class="line">        array[i] &#x3D; 0;</span><br><span class="line">    &#125;</span><br><span class="line">    int j&#x3D;0;</span><br><span class="line">    int k&#x3D;0;</span><br><span class="line">    int c&#x3D;0;</span><br><span class="line">    clock_t start&#x3D;clock();</span><br><span class="line">    while(j++&lt;repeat_times)&#123;</span><br><span class="line">        if(k&#x3D;&#x3D;array_size)&#123;</span><br><span class="line">            k&#x3D;0;</span><br><span class="line">        &#125;</span><br><span class="line">        c &#x3D; array[k++];</span><br><span class="line">    &#125;</span><br><span class="line">    clock_t end &#x3D;clock();</span><br><span class="line">    printf(&quot;%lu\n&quot;, timediff(start,end));</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果我们把这些数据做成折线图后就会发现：总执行时间在数组大小超过64Bytes时有较为明显的拐点（当然，由于博主是在自己的Mac笔记本上测试的，会受到很多其他程序的干扰，因此会有波动）。原因是当数组小于64Bytes时数组极有可能落在一条Cache Line内，而一个元素的访问就会使得整条Cache Line被填充，因而值得后面的若干个元素受益于缓存带来的加速。而当数组大于64Bytes时，必然至少需要两条Cache Line，继而在循环访问时会出现两次Cache Line的填充，由于缓存填充的时间远高于数据访问的响应时间，因此多一次缓存填充对于总执行的影响会被放大，最终得到下图的结果： <img src="http://cenalulu.github.io/images/linux/cache_line/cache_line_size2.png" alt="cache_size"> 如果读者有兴趣的话也可以在自己的linux或者MAC上通过<code>gcc cache_line_size.c -o cache_line_size</code>编译，并通过<code>./cache_line_size</code>执行。</p>
<p><strong>了解Cache Line的概念对我们程序猿有什么帮助？</strong> 我们来看下面这个C语言中<a href="http://qr.ae/ja9ov" target="_blank" rel="noopener">常用的循环优化例子</a> 下面两段代码中，第一段代码在C语言中总是比第二段代码的执行速度要快。具体的原因相信你仔细阅读了Cache Line的介绍后就很容易理解了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for(int i &#x3D; 0; i &lt; n; i++) &#123;</span><br><span class="line">    for(int j &#x3D; 0; j &lt; n; j++) &#123;</span><br><span class="line">        int num;    </span><br><span class="line">        &#x2F;&#x2F;code</span><br><span class="line">        arr[i][j] &#x3D; num;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">for(int i &#x3D; 0; i &lt; n; i++) &#123;</span><br><span class="line">    for(int j &#x3D; 0; j &lt; n; j++) &#123;</span><br><span class="line">        int num;    </span><br><span class="line">        &#x2F;&#x2F;code</span><br><span class="line">        arr[j][i] &#x3D; num;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="CPU-Cache-是如何存放数据的"><a href="#CPU-Cache-是如何存放数据的" class="headerlink" title="CPU Cache 是如何存放数据的"></a>CPU Cache 是如何存放数据的</h2><h4 id="你会怎么设计Cache的存放规则"><a href="#你会怎么设计Cache的存放规则" class="headerlink" title="你会怎么设计Cache的存放规则"></a>你会怎么设计Cache的存放规则</h4><p>我们先来尝试回答一下那么这个问题：</p>
<blockquote>
<p>假设我们有一块4MB的区域用于缓存，每个缓存对象的唯一标识是它所在的物理内存地址。每个缓存对象大小是64Bytes，所有可以被缓存对象的大小总和（即物理内存总大小）为4GB。那么我们该如何设计这个缓存？</p>
</blockquote>
<p>如果你和<a href="http://cenalulu.github.io/" target="_blank" rel="noopener">博主</a>一样是一个大学没有好好学习基础/数字电路的人的话，会觉得最靠谱的的一种方式就是：Hash表。把Cache设计成一个Hash数组。内存地址的Hash值作为数组的Index，缓存对象的值作为数组的Value。每次存取时，都把地址做一次Hash然后找到Cache中对应的位置操作即可。 这样的设计方式在高等语言中很常见，也显然很高效。因为Hash值得计算虽然耗时(<a href="http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed" target="_blank" rel="noopener">10000个CPU Cycle左右</a>)，但是相比程序中其他操作（上百万的CPU Cycle）来说可以忽略不计。而对于CPU Cache来说，本来其设计目标就是在几十CPU Cycle内获取到数据。如果访问效率是百万Cycle这个等级的话，还不如到Memory直接获取数据。当然，更重要的原因是在硬件上要实现Memory Address Hash的功能在成本上是非常高的。</p>
<h4 id="为什么Cache不能做成Fully-Associative"><a href="#为什么Cache不能做成Fully-Associative" class="headerlink" title="为什么Cache不能做成Fully Associative"></a>为什么Cache不能做成Fully Associative</h4><p>Fully Associative 字面意思是全关联。在CPU Cache中的含义是：如果在一个Cache集内，任何一个内存地址的数据可以被缓存在任何一个Cache Line里，那么我们成这个cache是Fully Associative。从定义中我们可以得出这样的结论：给到一个内存地址，要知道他是否存在于Cache中，需要遍历所有Cache Line并比较缓存内容的内存地址。而Cache的本意就是为了在尽可能少得CPU Cycle内取到数据。那么想要设计一个快速的Fully Associative的Cache几乎是不可能的。</p>
<h4 id="为什么Cache不能做成Direct-Mapped"><a href="#为什么Cache不能做成Direct-Mapped" class="headerlink" title="为什么Cache不能做成Direct Mapped"></a>为什么Cache不能做成Direct Mapped</h4><p>和Fully Associative完全相反，使用Direct Mapped模式的Cache给定一个内存地址，就唯一确定了一条Cache Line。设计复杂度低且速度快。那么为什么Cache不使用这种模式呢？让我们来想象这么一种情况：一个拥有1M L2 Cache的32位CPU，每条Cache Line的大小为64Bytes。那么整个L2Cache被划为了<code>1M/64=16384</code>条Cache Line。我们为每条Cache Line从0开始编上号。同时32位CPU所能管理的内存地址范围是<code>2^32=4G</code>，那么Direct Mapped模式下，内存也被划为<code>4G/16384=256K</code>的小份。也就是说每256K的内存地址共享一条Cache Line。但是，这种模式下每条Cache Line的使用率如果要做到接近100%，就需要操作系统对于内存的分配和访问在地址上也是近乎平均的。而与我们的意愿相反，为了减少内存碎片和实现便捷，操作系统更多的是连续集中的使用内存。这样会出现的情况就是0-1000号这样的低编号Cache Line由于内存经常被分配并使用，而16000号以上的Cache Line由于内存鲜有进程访问，几乎一直处于空闲状态。这种情况下，本来就宝贵的1M二级CPU缓存，使用率也许50%都无法达到。</p>
<h4 id="什么是N-Way-Set-Associative"><a href="#什么是N-Way-Set-Associative" class="headerlink" title="什么是N-Way Set Associative"></a>什么是N-Way Set Associative</h4><p>为了避免以上两种设计模式的缺陷，N-Way Set Associative缓存就出现了。他的原理是把一个缓存按照N个Cache Line作为一组（set），缓存按组划为等分。这样一个64位系统的内存地址在4MB二级缓存中就划成了三个部分（见下图），低位6个bit表示在Cache Line中的偏移量，中间12bit表示Cache组号（set index），剩余的高位46bit就是内存地址的唯一id。这样的设计相较前两种设计有以下两点好处：</p>
<ul>
<li>给定一个内存地址可以唯一对应一个set，对于set中只需遍历16个元素就可以确定对象是否在缓存中（Full Associative中比较次数随内存大小线性增加）</li>
<li>每<code>2^18(256K)*16(way)</code>=<code>4M</code>的连续热点数据才会导致一个set内的conflict（Direct Mapped中512K的连续热点数据就会出现conflict）</li>
</ul>
<p><img src="http://cenalulu.github.io/images/linux/cache_line/addr_bits.png" alt="addr"></p>
<p><strong>为什么N-Way Set Associative的Set段是从低位而不是高位开始的</strong></p>
<p>下面是一段从<a href="http://danluu.com/3c-conflict/#fn3" target="_blank" rel="noopener">How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses</a>摘录的解释：</p>
<blockquote>
<p>The vast majority of accesses are close together, so moving the set index bits upwards would cause more conflict misses. You might be able to get away with a hash function that isn’t simply the least significant bits, but most proposed schemes hurt about as much as they help while adding extra complexity.</p>
</blockquote>
<p>由于内存的访问通常是大片连续的，或者是因为在同一程序中而导致地址接近的（即这些内存地址的高位都是一样的）。所以如果把内存地址的高位作为set index的话，那么短时间的大量内存访问都会因为set index相同而落在同一个set index中，从而导致cache conflicts使得L2, L3 Cache的命中率低下，影响程序的整体执行效率。</p>
<p><strong>了解N-Way Set Associative的存储模式对我们有什么帮助</strong></p>
<p>了解N-Way Set的概念后，我们不难得出以下结论：<code>2^(6Bits &lt;Cache Line Offset&gt; + 12Bits &lt;Set Index&gt;)</code> = <code>2^18</code> = <code>256K</code>。即在连续的内存地址中每256K都会出现一个处于同一个Cache Set中的缓存对象。也就是说这些对象都会争抢一个仅有16个空位的缓存池（16-Way Set）。而如果我们在程序中又使用了所谓优化神器的“内存对齐”的时候，这种争抢就会越发增多。效率上的损失也会变得非常明显。具体的实际测试我们可以参考： <a href="http://danluu.com/3c-conflict/#fn3" target="_blank" rel="noopener">How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses</a> 一文。 这里我们引用一张<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a> 中的测试结果图，来解释下内存对齐在极端情况下带来的性能损失。 <img src="http://igoro.com/wordpress/wp-content/uploads/2010/02/assoc_big1.png" alt="memory_align"></p>
<p>该图实际上是我们上文中第一个测试的一个变种。纵轴表示了测试对象数组的大小。横轴表示了每次数组元素访问之间的index间隔。而图中的颜色表示了响应时间的长短，蓝色越明显的部分表示响应时间越长。从这个图我们可以得到很多结论。当然这里我们只对内存带来的性能损失感兴趣。有兴趣的读者也可以阅读<a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">原文</a>分析理解其他从图中可以得到的结论。</p>
<p>从图中我们不难看出图中每1024个步进，即每<code>1024*4</code>即4096Bytes，都有一条特别明显的蓝色竖线。也就是说，只要我们按照4K的步进去访问内存(内存根据4K对齐），无论热点数据多大它的实际效率都是非常低的！按照我们上文的分析，如果4KB的内存对齐，那么一个240MB的数组就含有61440个可以被访问到的数组元素；而对于一个每256K就会有set冲突的16Way二级缓存，总共有<code>256K/4K</code>=<code>64</code>个元素要去争抢16个空位，总共有<code>61440/64</code>=<code>960</code>个这样的元素。那么缓存命中率只有1%，自然效率也就低了。</p>
<p>除了这个例子，有兴趣的读者还可以查阅另一篇国人对Page Align导致效率低的实验：<a href="http://evol128.is-programmer.com/posts/35453.html" target="_blank" rel="noopener">http://evol128.is-programmer.com/posts/35453.html</a></p>
<p>想要知道更多关于内存地址对齐在目前的这种CPU-Cache的架构下会出现的问题可以详细阅读以下两篇文章：</p>
<ul>
<li><a href="http://danluu.com/3c-conflict/" target="_blank" rel="noopener">How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses</a></li>
<li><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></li>
</ul>
<hr>
<h2 id="Cache淘汰策略"><a href="#Cache淘汰策略" class="headerlink" title="Cache淘汰策略"></a>Cache淘汰策略</h2><p>在文章的最后我们顺带提一下CPU Cache的淘汰策略。常见的淘汰策略主要有<code>LRU</code>和<code>Random</code>两种。通常意义下LRU对于Cache的命中率会比Random更好，所以CPU Cache的淘汰策略选择的是<code>LRU</code>。当然也有些实验显示<a href="http://danluu.com/2choices-eviction/" target="_blank" rel="noopener">在Cache Size较大的时候Random策略会有更高的命中率</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CPU Cache对于程序猿是透明的，所有的操作和策略都在CPU内部完成。但是，了解和理解CPU Cache的设计、工作原理有利于我们更好的利用CPU Cache，写出更多对CPU Cache友好的程序</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/" target="_blank" rel="noopener">Gallery of Processor Cache Effects</a></li>
<li><a href="http://danluu.com/3c-conflict/" target="_blank" rel="noopener">How Misaligning Data Can Increase Performance 12x by Reducing Cache Misses</a></li>
<li><a href="http://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Memory/introCache.html" target="_blank" rel="noopener">Introduction to Caches</a></li>
</ol>
]]></content>
      <categories>
        <category>计算机体系结构</category>
        <category>cache</category>
      </categories>
      <tags>
        <tag>计算机体系结构</tag>
      </tags>
  </entry>
</search>
